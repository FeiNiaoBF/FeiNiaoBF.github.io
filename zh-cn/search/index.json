[{"content":"Hello 你好，这是，这里面是记录我对自己的博客 web 更新的日记。\nMarch 10，2023 博客使用 hugo 了\nApril 20, 2023 我使用了图床，蛮好用的 😁\nApril 25, 2023 我更新了一些社交方式\n更新一下我的博客的配置\nMar 10，2024 好久不见了，这一次我把近一年的笔记进行一个整理，然后更新到了博客上。 也做了许多的计划和之后的规划\n","date":"2023-03-08T19:56:58+08:00","image":"https://s2.loli.net/2024/04/08/bN8h1ZycAzF5MHu.jpg","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%9B%B4%E6%96%B0%E6%97%A5%E8%AE%B0/","title":"博客搭建更新日记✨"},{"content":"计算机语言基础 C 语言 项目练习\nGo 语言 ———\u0026gt; Go 语言学习\n项目练习\npython 语言 项目练习\n数据结构 数据结构是对计算机高级语言最能体现打基础的学习，目前有许多常见的数据结构，我喜欢分类来处理。\n基础结构 数组：是一种线性表数据结构，用于存储相同类型的数据元素。\n二分搜索 冒泡排序 动态规划 \u0026hellip; \u0026hellip; 链表：由一系列节点组成的数据结构，每个节点包含数据和指向下一个节点的指针。\n反转链表 环形链表 LRU 缓存算法 \u0026hellip; \u0026hellip; 栈：一种遵循后进先出（LIFO）原则的数据结构，只允许在表的一端进行插入和删除操作。\n队列：一种遵循先进先出（FIFO）原则的数据结构，允许在表的一端进行插入，在另一端进行删除操作。\n树：一种非线性数据结构，由节点组成，节点之间存在层次关系。\n图：由节点（或顶点）和边组成的数据结构，用于表示多对多的关系。\n其他结构 并查集：一种用于处理不相交集合的数据结构，常用于解决连接性问题。 字典树：一种用于快速检索的树形数据结构，常用于字符串检索。 散列表：利用哈希函数将关键字映射到表中一个位置来访问记录的数据结构。 树状数组：一种高效的数据结构，用于维护序列前缀和的动态查询。 映射：一种将键映射到值的抽象数据类型，常用于快速查找。 集合：一种抽象数据类型，用于存储互不相同的元素的集合。 真实世界 在实际项目中，数据结构和算法的选择取决于具体的应用场景和问题需求。一般来说，对于不涉及高精尖、复杂算法的项目，可以尽量选择简单的数据结构。以下是一些建议和实践：\n根据场景选择数据结构：静态数组适合元素不超过 100 的场合，动态数组适合元素不超过 1000 的场合，链表适合元素不超过 3000 的场合。在需要动态分配内存的场合，可以考虑使用静态内存，以提高程序稳定性。\n实际项目中的应用：数据结构和算法在实际项目中扮演着重要角色，可以通过实际项目场景来说明一种数据结构解决了什么实际问题，以及其各种操作时间复杂度、优缺点等。这有助于理解数据结构在编程中的重要性。\n权衡选择：在实际开发中，需要权衡选择使用哪种数据结构和算法。除了考虑算法的时间复杂度、空间复杂度，还需要考虑其在具体场景下的执行效率、易用性、维护成本等因素\n综上所述，实际项目中的数据结构和算法选择应该根据具体的应用场景和问题需求进行权衡和取舍，以达到最优的解决方案。\n算法（AI） 算法是解决问题的一系列清晰指令，是计算机科学的基础。在实际开发中，选择合适的数据结构和算法对程序的性能和效率至关重要。在学习算法时，需要权衡选择使用哪种数据结构和算法，不能简单地用复杂度来表示执行性能。此外，编程算法面试经验总结中提到，算法面试常涉及的主题、考察形式和评价方式，对求职备考的朋友们有所帮助。另外，算法也在机器学习领域有着广泛的应用，比如预测住房价格、探索客户的人口统计学数据以确定模式等。在实际开发中，对于数组的算法，可以通过合并两个有序数组来进行实现。对于统计相同数字出现的次数，可以利用数组元素下标对应数字，用数组元素的值表示对应数字出现的次数，这是一种典型的空间换时间的算法。如果整数的范围是 1 到 n，可以考虑使用其他的算法来实现。\n关键要点 目的和问题解决： 算法的设计旨在解决特定问题或执行特定任务。它们用于执行各种计算和操作，从简单的搜索和排序到复杂的图算法和机器学习。 输入和输出： 算法接受一个或多个输入，通过执行一系列计算操作，产生一个输出。输入可以是数据、问题描述或其他形式的信息。 有限性： 算法是有限步骤的集合，每一步都可以在有限的时间内完成。这确保了算法的执行是可以终止的。 确定性： 算法的每一步都是确定性的，即对于给定的输入，它总是产生相同的输出。这使得算法在不同的环境中具有可重复性。 效率： 算法的效率是一个关键方面，通常通过时间复杂度和空间复杂度来衡量。好的算法能够以较低的时间和空间开销解决问题。 可读性和可维护性： 除了效率，算法的可读性和可维护性也是重要的。一个清晰、简单、易于理解的算法更容易被其他人理解和维护。 算法的分类 搜索算法： 用于在数据集中查找特定元素的算法，如线性搜索和二分搜索。 排序算法： 对一组元素进行排列的算法，例如冒泡排序、快速排序、归并排序等。 图算法： 处理图数据结构的算法，包括深度优先搜索、广度优先搜索、最短路径算法等。 动态规划： 将复杂问题分解为简单子问题，并通过保存已解决的子问题的解来加速求解的算法。 贪心算法： 在每一步选择中都采取当前状态下最好或最优的选择，从而希望得到全局最好或最优解的算法。 回溯算法： 通过不断试错找到问题的解，是一种递归的算法。 分治算法： 将问题分解成相互独立且与原问题相同的子问题，然后递归地解决子问题。 随机化算法： 使用随机数来解决问题的算法，例如快速排序的随机化版本。 机器学习算法： 用于构建模型、分类和预测的一系列算法，如决策树、支持向量机、神经网络等。 算法是计算机科学的核心，它们不仅仅是问题求解的工具，也是构建复杂系统和应对实际挑战的基础。深入理解和熟练运用各种算法，有助于提高问题解决和计算机科学建模的能力。\n体系结构 操作系统 操作系统的具体学习目录\n计算机网络 CS 后续学习路径 为自身打造的路径\n目标：人工智能Artificial intelligence 数学 Search\u0026mdash;GraphTheory\nKnowledge\u0026mdash;BooleanLogic\nUncertainty\u0026mdash;Probability\n目标：应用程序开发Application Developer\nFull Stack\n目标：计算机图形学Computer graphics\n目标：软件工程Software engineering\n","date":"2024-03-10T15:58:41+08:00","image":"https://s2.loli.net/2024/04/08/Xej8au1VkhZN4HT.jpg","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/cs%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/","title":"CS学习计划"},{"content":"思 这里面是我记录自己个人在学习过程中的一些对学习的看法和问题\n输出知识的法宝 对问题的提问 对于大多数的问题而言，有些在网上查找、询问资历高的同行等等方式。\n《提问的智慧》精读注解版 计算机的哲学 什么是抽象思维 什么是流水线 ","date":"2023-04-24T19:04:47+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/%E7%AE%80%E5%8D%95%E6%98%AF%E7%A8%B3%E5%AE%9A%E7%9A%84%E5%89%8D%E6%8F%90/","title":"简单是稳定的前提"},{"content":"Introduction 一般问题 Go 语言的显式范围和垃圾回收和变量逃逸 在一个包范围内声明的变量，如果在函数内部声明了同名变量，那么这两个变量是不同的实体，作用域不同，垃圾回收器会分别管理它们。 发生逃逸的情况包括：变量生命周期不确定、变量占用内存较大、变量不确定类型、变量不确定大小。 使用更好的注释 Go 的命名规则 对于类型中的底层类型 内置类型中 string 是否和 c 中的一样有 \\0 没有 C 语言定义字符用的结尾 \\0，而且获取长度的时间复杂度是常数时间，消除了获取字符串长度的开销 type boolean = bool 和 type boolean bool 区别 定义声明和别名声明 常量和变量之间的转化 常量可以赋值给变量，但变量不能赋值给常量，因为常量的值在编译时就必须是确定的。 常量可以转换为不同类型的变量，只要这个转换是安全的，即不会丢失信息或导致溢出。 变量之间也可以进行类型转换，但必须满足类型转换的规则 定义时传递方法不同 数组是值类型，拥有固定的长度，重点是它是值传递的，所以说他是值类型。切片的话则是传递地址或者说指针，所以说它是引用类型，而且他的长度是可以变化的可以扩容的。 主要问题 Go Modules 的使用有感 Go Package 的使用 Goroutine 并行的开始 Go 中的 Interfaces type ","date":"2024-05-13T09:13:33+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/%E9%97%AE%E9%A2%98%E9%9B%86/","title":"问题集"},{"content":"成功软件 4.24 主要是以项目问问题\u0026mdash;后端项目小银行 问具体数据表 有三个表，数据库的范式 怎么使用的（我这里忘记有一个表是做什么了 :( ） ORM: 第三方的库的 sqlc 项目中具体的 API 的实现 Go 中的 Gin RESTful 配置管理（这个是项目的配置，不是面对用户的） 吃豆人的项目 Go 协程的使用（我没说清楚） Docker 的使用 怎么理解容器-容器为什么叫容器 映像和容器的区别 Docker 是什么 Docker File（我不会就没问） docker run 的使用 Github Action Makefile 用来做什么 Go 中的 context 的使用（我没具体的看过） Go 的标准库有哪些使用和了解 一些操作系统的问题 文件系统-log lock-原子操作 Linux 常用命令 git 常用命令 有一串每个提交它那有一串那个数字英文的组合 - SHA-1哈希算法-哈希值 ","date":"2024-05-13T09:13:20+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/%E9%9D%A2%E8%AF%95%E9%9B%86/","title":"面试集"},{"content":"UTF-8编码和 Unicode 文本区别 在 Golang 中字符串的底层结构字节使用 UTF-8 编码来表示 Unicode 文本\n其中 Unicode 是一个字符集，定义了字符和它们的唯一代码点，而 UTF-8 是一种编码方式，用于将 Unicode 字符表示为字节序列。\n字符串 Go 语言中的字符串值是一个可空的字节序列，字节序列中的字节个数称为该字符串的长度。String 类型其实是一个\u0026quot;描述符”，它本身并不真正存储字符串数据，而是由一个指向底层存储的指针和字符串的长度字段组成的\n","date":"2024-05-13T09:10:39+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/strings/","title":"Strings"},{"content":"Go 语言中的数据结构 基础数据结构 数组（Array） - 由固定长度的相同类型元素组成的数据结构。 切片（Slice） - 由数组构成的动态长度序列，提供了更灵活的操作方式。 映射（Map） - 存储键值对的集合，用于快速检索数据。 结构体（Struct） - 可以包含不同类型字段的复合数据类型。 其他数据结构和类型 通道（Channel） - 用于在 Go 协程之间进行通信的类型。 接口（Interface） - 定义对象的行为，是一种抽象类型。 指针（Pointer） - 存储变量的内存地址，用于直接访问内存中的值。 通道（Channel） 接口（Interface） 指针（Pointer） 命名规范 注意：\n首字母大小写： 以大写字母开头的标识符是 public 的（可导出的），可以被其他包访问。以小写字母开头的标识符是私有的，只能在当前包内访问。\n在 Go 语言中，有一些命名规范适用于不同的命名情况。以下是一些常见的命名规范：\n包名：包名应该使用单数形式，且应该是小写的，例如 utils。 文件名：文件名应该全部使用小写字母，可以包含下划线 _，例如 my_file.go。 变量：变量名使用驼峰命名法，例如 myVariable。私有变量的命名应该以小写字母开头，公共变量则以大写字母开头。 常量：常量的命名应该全部使用大写字母，可以包含下划线 _，例如 MAX_SIZE。 函数：函数名同样使用驼峰命名法，例如 calculateTotal。 结构体：结构体的命名同样使用驼峰命名法，例如 type MyStruct struct。 接口：接口的命名同样使用驼峰命名法，例如 type MyInterface interface。 枚举：枚举的命名同样使用驼峰命名法，例如 type Color int。 在 Go 语言中，命名变量时有一些常见的命名规范，这些规范有助于编写清晰、易读的代码。\n使用驼峰命名法：变量名应该使用驼峰命名法，即除第一个单词外，其余单词的首字母大写，例如 myVariable。 使用有意义的名称：变量名应该具有描述性，能够清晰地表达变量的用途和含义。 避免使用单个字符作为变量名：除非是临时变量或者循环变量，否则应该避免使用单个字符作为变量名，以提高代码的可读性。 使用短小的名称：变量名应该尽量简洁，但又能清晰表达变量的含义。 使用全大写命名的常量：在 Go 语言中，全大写的变量名通常用于表示常量。 遵循约定俗成的命名规范：Go 语言社区有一些常见的命名约定，比如用 i 表示循环变量，用 err 表示错误变量等，建议遵循这些约定以保持代码风格的一致性。 这些命名规范有助于编写清晰、易读的代码，并且有助于提高代码的可维护性。\n","date":"2024-05-13T09:10:19+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/datatype/","title":"DataType"},{"content":"入门资料 官方Docs ，官方的文档是最好的入门资料，强烈推荐看，如果可以完整看完、理解并实践的话说明就吃透 Go 语言了。\nGo by Example，是一个集合了 Go 语言基础类型、特性等众多示例的网站，你可以通过这些实例来初步了解和学习 Go 语言的使用。\nLearn GO with Tests，该网址是通过使用 Test 来学习 Go 的开源书籍，在其中作者将以如何使用 Go 自带的 testing 库来一步一步的认识 Go 语言当中的类型和其他特性。从中将学习到 TDD 的技术、Go 语言的单元测试、学习测试驱动开发等，很大的提升自己的 Go 语言的使用和开发\n社交平台 Reddit 上的go社区\n书籍推荐 ","date":"2024-05-13T09:08:51+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/resource/","title":"Resource"},{"content":"Hello, Golang Go 语言是 Google 开发的一种静态强类型、编译型、并发型，并具有垃圾回收功能的编程语言。\n下载地址：Downloads - The Go Programming Language\n快速开始 下载 Go 到你的学习机上，检查 go 的现状 1 go version 在你喜欢的 Workspace 上 Create a new directory 1 mkdir gowork 添加一个名为 hello.go 的文件，在其中输入代码 In vim, vscode \u0026hellip;\n1 2 3 4 5 6 7 package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Hello, world\u0026#34;) } In shell\n1 2 3 4 5 6 7 8 echo \u0026#34;package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Hello, world\u0026#34;) }\u0026#34; \u0026gt;\u0026gt; hello.go 运行它 1 go run hell.go Welcome to Go!\n其他 ","date":"2024-05-13T09:08:32+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/learningpath/","title":"LearningPath"},{"content":"资料来源: cs61c\nCache 可以说是计算机技术革命中最伟大的想法了\n想一个问题：在我们的电脑里，指令是怎么控制内存里的东西的？因为我们要运行电脑除了 CPU 以外我们要向外 拿取 数据才能执行一系列的指令，这样电脑才算运行起来。\n让我们来看下面的这张图，这是十分完整的计算机组成结构：\nComponents of a Computer 我们可以从中看到在 CPU 需要运行一个进程的时候，首先会将指令告诉主存（main memory）, 然后开始在主存中找地址（Address）找到后加载到在 CPU 内部通用寄存器（register）然后开始执行 执行完后再写入主存中。\n在这里面还有一个步骤，memory 要先向 disk 中读取数据\n其实现实中，CPU 通用寄存器的速度和主存之间存在着太大的差异。两者之间的速度大致如下关系： Oh!!! 它们相差 1,000 倍左右，这是无法想像的，就比如当我前 1 ns 的时候 CPU 已经做完了，而我还要等 1000 ns 的 memory 的时间，因此在我们看来 CPU 此时是空闲的，大大的浪费了。\n因此，如果我们可以提升主存的速度，那么对于系统来说将会获得很大的性能提升。但我们试图提升主存的速度和容量，又期望其成本很低，这就有点难为人了。因此，我们有一种折中的方法，那就是制作一块速度极快但是容量极小的存储设备。那么其成本也不会太高。这块存储设备我们称之为 cache。在硬件上，我们将 cache 放置在 CPU 和 主存 之间，作为主存数据的缓存。当 CPU 试图从主存中 load/store 数据的时候， CPU 会首先从 cache 中查找对应地址的数据是否缓存在 cache 中。如果其数据缓存在 cache 中，直接从 cache 中拿到数据并返回给 CPU。\n其实类比的话，我蛮喜欢 CS 61 c 里面的 Library Analogy，而我自己的想法是有点像现在的物流运输：对一些物品都有一个 主要的仓库，而也有一些 本地仓，当我要送东西的时候我先去看看 本地仓 有没有，没有就再去 主仓 去看看，但时间上就没有本地仓的快\n[[2. Areas/01 Blog/03-ComputerSystems/cs61c/SRAM vs. DRAM vs. Disk]]\nMemory Hierarchy 好的现在我们知道了 cache 的出现了，而下面的图是说明了对于不同的内存级别 Cache Cache 的级别 每一级的 cache 就是每一个下级内存的副本\nCahe 的速度在一定程度上同样影响着系统的性能. 当 cache 中没有缓存我们想要的数据的时候，依然需要漫长的等待从主存中 load 数据。为了进一步提升性能，引入多级 cache。前面提到的 cache，称之为 L 1 cache（第一级 cache）。我们在 L 1 cache 后面连接 L 2 cache，在 L 2 cache 和主存之间连接 L 3 cache。等级越高，速度越慢，容量越大。\nTemporal Locality (时间局部性) If a memory location is referenced then it will tend to be referenced again soon\n比如说我用过一次这个地址, 我保存起来以防我下次使用\nSpatial Locality (空间局部性) If a memory location is referenced, the locations with nearby addresses will Tend to be referenced soon\n比如一个数组，在我读取的时候它会把数组左右的都读取了\nCache Hit vs Cache Miss 在我要对数据进行查找的时候会出现两种情况 Cache Hit \u0026amp; Cache Miss.\nCache hit 你要查找的数据 在缓存中 从缓存中检索数据并将其带到处理器.\nCache miss 你要查找的数据 不在缓存中 去内存中找数据，把数据放到缓存中，带到处理器中\nCache 的工作原理 现在我们来继续说一些快取的工作原理, 在此之前先来说一下的一些名词 什么是 line/tag/index/offset/valid\nline: 我们将 cache 平均分成相等的很多块，每一个块大小称之为 cache line 也可以叫 cache block，其大小是 cache line size。 tag: Used to identify the data (用于识别数据)。每条 Cache Line 前都会有一个独立分配的内存来存 tag，其就是内存地址的前 Nbits。 $$ addressbits - offsetbits $$ offset: Identifies the byte offset (标识字节偏移量)。一般是低位后几位。 $$ offset = log_2(line size) $$ index: 内存地址后续的 bits 则是在这\u0026ndash;Way 的是 Cache Line 索引，可以索引 Cache Line。 Valid bit: Tells you if the data stored at a given cache line is valid (告诉您存储在给定缓存行中的数据是否有效) 一个地址访问要映射到 Cache 中，地址被分成三个字段：tag，set index, block offset。这样，通过一个物理地址就可以获取数据或指令在缓存中的位置 (set, way, byte))\nDirect mapped cache (直接映射缓存) 优点：直接映射缓存在硬件设计上会更加简单，因此成本上也会较低。\n一句话, 我一个个的加载进入 cache, 当我的 cache 满了我就转头再来一遍\n只适合于大容量Cache\n缺点: 继续访问下面的地址时，依然会 cache 缺失。这就相当于每次访问数据都要从主存中读取，所以 cache 的存在并没有对性能提升有效, 有 cache颠簸 (每个主存块只有一个固定位置可存放，容易产生冲突)\nTwo-way set associative cache (两路组相连缓存) Cache 分了 2 组\n优点: 减少 cache 颠簸出现频率\n组相联映射实际上是直接映射和全相联映射的折中方案\n缺点: 增加硬件设计复杂读、成本较高 (需要比较多个 cache line 的 TAG)\nFully Associative Cache (全相连缓存) 优点: 最大程度的降低 cache 颠簸的频率\n只适合于小容量Cache\n缺点: 增加硬件设计复杂读、成本较高 (需要比较多个 cache line 的 TAG)\n扩展：[[More Eviction Policies]] 寻找 Hit 的电路\n[[Types of Misses]]\nComparisons 三个 cache 的区别之分 需补充\n","date":"2024-05-13T08:39:14+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/cache-notes/","title":"Cache Notes"},{"content":"","date":"2024-03-14T23:07:09+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/pipe/","title":"Pipe"},{"content":"抽象表述 文件描述符是一个非零整数\n在操作系统中去让机器认识：（不同的）文件、socket、外部 I/O 资源等等是不简单的事情，但是机器认识数字，那我们就可以利用这个特性，抽象的描述以上的这些资源，因此文件描述符 就是来表述资源的，为了不打乱资源的使用，系统中对有着一张全局的表 、而每个进程也有自己的表 。当进程打开一个文件时，操作系统在全局文件描述符表和进程文件描述符表中都会有一个对应的条目，它们保持同步。\n通俗来说，每个进程在启动时都会自动打开三个标准文件描述符：\n文件描述符0（stdin）：标准输入，通常是键盘输入。 文件描述符1（stdout）：标准输出，通常是屏幕上的文本输出。 文件描述符 2（stderr）：标准错误输出，通常也是屏幕上的文本输出，但通常用于显示错误消息。 而在之后的操作中：进程打开或创建一个文件时，操作系统就为这个文件标识一个文件描述符，它写入表中作为其中的一个索引，为接下来的 read 和 write 作准备。 使用 既然文件描述符是操作系统提供的一种资源抽象，那它就可以允许（系统）程序通过一个数字来访问文件和 I/O 资源，而无需关心机器底层的具体实现细节。\n在 Unix/类 Unix 的系统中调用 read() 和 write() 从文件描述符所指的文件中读或者写 n 个字节，如：\n1 2 3 4 5 char buf[512]; n = read(0, buf, sizeof(buf)); n = write(1, buf, sizeof(buf)); 而且它们的返回的是实际读或写的字节数，那么 n 小于 0 的时候就发生了错误。\n那么这就有新的问题了，我这里用的是标准输入和标准输出，之前说了，当文件打开或创建的时候有标识文件描述符，而且系统是按顺序来标识的，直到最大（），也就是说，有新文件打开，它文件描述符是 3 那么我怎么用 read 和 write 对 3 操作，这里就有一个 Unix 伟大的设计了\u0026mdash; I/O 重定向\n1 2 3 4 5 6 7 8 9 // cat \u0026lt; input.txt char *argv[2]; argv[0] = \u0026#34;cat\u0026#34;; ### argv[1] = 0; if(fork() == 0) { close(0); open(\u0026#34;input.txt\u0026#34;, O_RDONLY); exec(\u0026#34;cat\u0026#34;, argv); } 以上的操作是：fork 一个子进程（它有父进程的表和一切），用 close 把标准输入关闭，用 open 打开新文件 \u0026mdash; input.txt ，系统是顺序标识的，所以 input.txt 在子进程中是 0 而 cat 是指向标准输入的，即，代码将 input.txt 输入到 cat，再输出到 shell 中。\n","date":"2024-03-10T16:39:03+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6/","title":"文件描述符"},{"content":"命令行的艺术\nMissing-Semester 计算机教育中缺失的一课\n基础 学习 Vim 。\n学会如何使用 man 命令去阅读文档。\nman bash [[Bash]] 学会使用 apropos 去查找文档\n知道有些命令并不对应可执行文件，而是在 Bash 内置好的，此时可以使用 help 和 help -d 命令获取帮助信息。\n你可以用 type 命令 来判断这个命令到底是可执行文件、shell 内置命令还是别名。\n学会重定向\n了解标准输出 stdout 和标准错误 stderr。 使用 \u0026gt; 和 \u0026lt; 来重定向输出和输入。 学会使用 | 来重定向管道。明白 \u0026gt; 会覆盖了输出文件而 \u0026gt;\u0026gt; 是在文件末添加。 学会使用 ssh 进行远程命令行登录。\n熟悉 Bash 中的任务管理工具。 \u0026amp;，ctrl-z，ctrl-c，jobs，fg，bg，kill\n学会使用特定符。\n通配符 * 学会基本的文件管理工具\n熟悉正则表达式 [[正则表达式]]\n学会使用 apt-get，yum，dnf 或 pacman 等来查找和安装软件包。\n","date":"2024-03-10T16:38:17+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%9A%84%E9%AD%85%E5%8A%9B/","title":"命令行的魅力"},{"content":" 上帝说要保存世界，于是有了文件系统\n我们之前都是在研究内存和 CPU 上的工作，对于它们而言只有在接通了电源时才可以使用，断电后就清除数据了。尤其是其中的随机存取存储器（RAM）芯片和 CPU 内存缓存（L1、L2和 L3 等）。因此我们急需一个可以永久保存数据的地方，一般这种 big 问题 都是优先有硬件来改变的，磁盘就出现了，它用来“永久”的保存数据。而新的问题就出现了，我怎么从磁盘中找寻、读取、存储数据呢？这就来看操作系统的文件管理系统的工作了。\n磁盘 （Disk） 磁盘是一种利用 磁记录技术 来实现存储的存储设备。磁记录技术利用磁性颗粒的磁化来保存数据。磁盘通常由一个或多个磁性盘组成，这些盘可以旋转。数据存储在盘片的表面上，而读写头则负责在盘片上读写数据。 磁盘的工作原理涉及到磁性颗粒的磁化和读写头的操作。当数据写入磁盘时，读写头会改变磁性颗粒的磁化方向，从而记录数据。而当需要读取数据时，读写头会扫描磁盘表面，通过检测磁性颗粒的磁化方向来读取数据。\n磁盘是对内存而言的存储设备，所以有时也叫辅存 。\n物理结构 想要了解磁盘的存储就要稍稍知道点磁盘的物理结构 ： 硬盘的物理结构一般由磁头与盘片、电动机、主控芯片与排线等部件组成；当主电动机带动盘片旋转时，副电动机带动一组（磁头）到相对应的盘片上并确定读取正面还是反面的碟面，磁头悬浮在碟面上画出一个与盘片同心的圆形轨道（磁道或称柱面），这时由磁头的磁感线圈感应碟面上的磁性与使用硬盘厂商指定的读取时间或数据间隔定位扇区，从而得到该扇区的数据内容；\n盘片（Platters）：磁盘中的盘片是类似于圆盘的结构，它们堆叠在一起并存储数据。 磁头（Head）：磁头是安装在硬盘驱动器臂上的设备，用于在磁盘的表面上读取或写入数据。 主轴（Spindle）：主轴是一个旋转的轴，用于将盘片固定在一个位置，以便读/写臂能够在盘片上获取数据。 执行器（Actuator）：执行器由读写头组成，它在硬盘上移动以保存或检索信息。 柱面（Cylinder）：这些是磁盘驱动器盘片上的圆形轨道，与磁盘中心的距离相等。 扇区（Sector）：盘上的每个磁道被等分为若干个弧段，这些弧段便是硬盘的扇区。硬盘的第一个扇区，叫做引导扇区。 sectors 和 blocks。\nsector通常是磁盘驱动可以读写的最小单元，它过去通常是512字节。 block通常是操作系统或者文件系统视角的数据。它由文件系统定义，在 XV 6 中它是 1024 字节。所以 XV 6 中一个 block 对应两个 sector。通常来说一个 block 对应了一个或者多个 sector。 工作方式 当硬盘读取数据时，磁头会感知盘片上的磁场，并将其转换为电信号，然后传输到计算机中。当硬盘写入数据时，磁头会通过电信号改变盘片上的磁场，从而实现数据的存储。这个过程是通过磁头在盘片上移动，根据需要读取或写入数据来完成的。\n随着科技的发展，现在不满足硬盘的速度和空间大小了，我们有新的磁盘：固态硬盘（SSD）是一种新型磁盘，它采用闪存存储技术，具有更快的读写速度和更大的存储容量。\nxv6 对于文件系统必须有将索引节点和内容块存储在磁盘上具体位置的方案。为此，xv6将磁盘划分为几个部分，文件系统不使用块0（它保存引导扇区）。块1称为超级块：它包含有关文件系统的元数据（文件系统大小（以块为单位）、数据块数、索引节点数和日志中的块数）。从2开始的块保存日志。日志之后是索引节点，每个块有多个索引节点。然后是位图块，跟踪正在使用的数据块。其余的块是数据块：每个都要么在位图块中标记为空闲，要么保存文件或目录的内容。超级块由一个名为 mkfs 的单独的程序填充，该程序构建初始文件系统。 通常来说，bitmap block，inode blocks和log blocks被统称为metadata block。它们虽然不存储实际的数据，但是它们存储了能帮助文件系统完成工作的元数据。\n在继续下面的内容时，要提出几点问题：\n文件系统怎么在磁盘上来表示数据？ 当系统出现崩溃时要怎么恢复？怎么保证 crash safety？ 辅存在性能上是 ms 级的，我怎么提高性能？ 缓冲区高速缓存 （Buffer cache） Buffer cache，这是为了解决磁盘到内存的性能问题和确保两个及其以上的进程不会互相影响而设计的。 它主要有两个任务：\n同步对磁盘块的访问，以确保磁盘块在内存中只有一个副本，并且一次只有一个内核线程使用该副本 缓存常用块，以便不需要从慢速磁盘重新读取它们。 1 2 3 4 5 6 7 8 struct { struct spinlock lock; struct buf buf[NBUF]; // Linked list of all buffers, through prev/next. // Sorted by how recently the buffer was used. // head.next is most recent, head.prev is least. struct buf head; } bcache; 在其中， buf 数据结构就是一个 block\n1 2 3 4 5 6 7 8 9 10 11 struct buf { int valid; // has data been read from disk? int disk; // does disk \u0026#34;own\u0026#34; buf? uint dev; uint blockno; struct sleeplock lock; uint refcnt; struct buf *prev; // LRU cache list struct buf *next; uchar data[BSIZE]; }; Buffer cache 层主要接口是 bread 和 bwrite；前者从 cache 中获取一个 buf，其中包含一个可以在内存中读取或修改的块的副本；后者将修改后的缓冲区写入磁盘上的相应块。可以说 Buffer cache 在内存中。而内核线程必须通过调用 brelse 释放缓冲区。Buffer cache 每个缓冲区使用一个 sleep lock，保证每个缓冲区每次只被一个线程使用。bread 返回一个上锁的缓冲区，brelse 释放该锁。\n在 Buffer cache 中，保存磁盘块的缓冲区数量是固定，说明如果文件系统请求并还未存放在缓存中的块多出固定值，那么 Buffer cache 必须回收当前保存其他块旧内容的缓冲区。Buffer cache 使用的是 LRU 回收机制。这样做的原因是认为最近使用最少的缓冲区是最不可能近期再次使用的缓冲区。\n来看看 bread 和 bwrite 的实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 // Return a locked buf with the contents of the indicated block. struct buf* bread(uint dev, uint blockno) { struct buf *b; b = bget(dev, blockno); if(!b-\u0026gt;valid) { virtio_disk_rw(b, 0); b-\u0026gt;valid = 1; } return b; } bread函数首先会调用bget函数，bget会为我们从buffer cache中找到block的缓存。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // Look through buffer cache for block on device dev. // If not found, allocate a buffer. // In either case, return locked buffer. static struct buf* bget(uint dev, uint blockno) { struct buf *b; acquire(\u0026amp;bcache.lock); // Is the block already cached? for(b = bcache.head.next; b != \u0026amp;bcache.head; b = b-\u0026gt;next){ if(b-\u0026gt;dev == dev \u0026amp;\u0026amp; b-\u0026gt;blockno == blockno){ b-\u0026gt;refcnt++; release(\u0026amp;bcache.lock); acquiresleep(\u0026amp;b-\u0026gt;lock); return b; } } // Not cached. // Recycle the least recently used (LRU) unused buffer. for(b = bcache.head.prev; b != \u0026amp;bcache.head; b = b-\u0026gt;prev){ if(b-\u0026gt;refcnt == 0) { b-\u0026gt;dev = dev; b-\u0026gt;blockno = blockno; b-\u0026gt;valid = 0; b-\u0026gt;refcnt = 1; release(\u0026amp;bcache.lock); acquiresleep(\u0026amp;b-\u0026gt;lock); return b; } } panic(\u0026#34;bget: no buffers\u0026#34;); } 这个 bget 的实现就是一个双链的向前遍历寻找指定、向后遍历寻找空位。 其中，如果有多个进程同时调用 bget 的话，其中一个可以获取 bcache 的锁并扫描 buffer cache。此时，其他进程是没有办法修改 buffer cache 的。之后，进程会查找 block number 是否在 cache 中，如果在的话将 block cache 的引用计数（refcnt）加1，表明当前进程对 block cache 有引用，之后再释放 bcache 的锁。如果有第二个进程也想扫描 buffer cache，那么这时它就可以获取 bcache 的锁。假设第二个进程也要获取 block 33的 cache，那么它也会对相应的 block cache 的引用计数加1。最后这两个进程都会尝试对 block 33的 block cache 调用 acquiresleep 函数。所以说在 xv6 中对 buffer cache 做任何修改的话，都必须持有 bcache 的锁；其次对单个 block 的 cache 做任何修改你需要持有该 block 的 sleep lock。\n而 bwrite 仅仅是为了将有锁块的内容写入到 virio disk 中。\n1 2 3 4 5 6 7 void bwrite(struct buf *b) { if(!holdingsleep(\u0026amp;b-\u0026gt;lock)) panic(\u0026#34;bwrite\u0026#34;); virtio_disk_rw(b, 1); } brelse 是在线程结束对 block 的操作时使用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // Release a locked buffer. // Move to the head of the most-recently-used list. void brelse(struct buf *b) { if(!holdingsleep(\u0026amp;b-\u0026gt;lock)) panic(\u0026#34;brelse\u0026#34;); releasesleep(\u0026amp;b-\u0026gt;lock); acquire(\u0026amp;bcache.lock); b-\u0026gt;refcnt--; if (b-\u0026gt;refcnt == 0) { // no one is waiting for it. b-\u0026gt;next-\u0026gt;prev = b-\u0026gt;prev; b-\u0026gt;prev-\u0026gt;next = b-\u0026gt;next; b-\u0026gt;next = bcache.head.next; b-\u0026gt;prev = \u0026amp;bcache.head; bcache.head.next-\u0026gt;prev = b; bcache.head.next = b; } release(\u0026amp;bcache.lock); } 当调用方使用完缓冲区后，它必须调用 brelse 来释放回收缓冲区。brelse 释放 sleep lock 并将缓冲区移动到链表的前面。移动缓冲区会使列表按缓冲区的使用频率排序：列表中的第一个缓冲区是最近使用的，最后一个是最近使用最少的。bget 中的两个循环利用了这一点：在最坏的情况下，对现有缓冲区的扫描必须处理整个列表，但首先检查最新使用的缓冲区（从 bcache.head 开始，然后是下一个指针），在引用局部性良好的情况下将减少扫描时间。\nblock cache的实现，这对于性能来说是至关重要的，因为读写磁盘是代价较高的操作，可能要消耗数百毫秒，而block cache确保了如果我们最近从磁盘读取了一个block，那么我们将不会再从磁盘读取相同的block。\n日志 （Logging） log ，操作系统最重要的一环，为保证 crash safety 而设计的机制。在使用机器中我们最担心出现的情况就是 crash 或者电力故障等可能会导致在磁盘上的文件系统处于不一致或者不正确状态的问题。而为了确保系统安全，要有可以阻止问题发生或修复的机制。 logging。这是一个最初来自于数据库世界的很流行的解决方案，现在很多文件系统都在使用 logging。之所以它很流行，是因为它是一个很好用的方法。接下来将会看到在 XV6中的简单 logging 实现。其中也包含了一些微妙的问题，讨论问题，解决问题。这也是为什么文件系统的 logging 值得学习的原因。\n首先，它可以确保文件系统的系统调用是原子性的。比如你调用 create/write 系统调用，这些系统调用的效果是要么完全出现，要么完全不出现，这样就避免了一个系统调用只有部分写磁盘操作出现在磁盘上. 其次，它支持快速恢复（Fast Recovery）。在重启之后，我们不需要做大量的工作来修复文件系统，只需要非常小的工作量。这里的快速是相比另一个解决方案来说，在另一个解决方案中，你可能需要读取文件系统的所有block，读取inode，bitmap block，并检查文件系统是否还在一个正确的状态，再来修复。而logging可以有快速恢复的属性。 最后，原则上来说，它可以非常的高效，尽管我们在XV6中看到的实现不是很高效。 先来想想，如果要对某文件做写操作一般的过程是怎么样的。\n创建该文件 找一个空闲的 inode 并更新 inode 的数据。 在 bit map 中找到当前目录的 data block 把 inode 加进去，告诉目录有新的数据。 再次更新了文件的 inode 。 写入数据 通过扫描 bitmap 找到一个还没有使用的 data block ，返回从 date blocks 中找到新地址。 在 xv 6 中一次可以写入一个字节的数据，也就是一个字符，所以有几个字符就调用几次新的 data block。 最后更新文件的 inode 的大小等信息。 这样看来数据流是从 memory 到 block cache 再到dick，log 在哪里？其实当我们在内存中缓存了bitmap block，假设写 block 45。当需要更新 bitmap 时，我们并不是直接写 block ，而是将数据写入到 log 中，并记录这个更新应该写入到 block 70。对于所有的写 block 都会有相同的操作，例如更新 inode，也会记录一条写 block 33 的 log。所以说 log 出现在要写入 block 的前面。 然后，在某个时间点，当文件系统的操作结束了，比如说我们前一节看到的4-5个写 block 操作都结束，并且都存在于 log 中，我们会 commit 文件系统的操作。这意味着我们需要在 log 的某个位置记录属于同一个文件系统的操作的个数，例如5。 之后当我们在 log 中存储了所有写 block 的内容时，如果我们要真正执行写入 dick 的操作，只需要将 block 从 log 分区移到文件系统分区。我们知道第一个操作该写入到 block 45，我们会直接将数据从 log 写到 block45，第二个操作该写入到 block 33，我们会将它写入到 block 33，依次类推。 最后，一旦完成了，就可以清除 log。清除 log 实际上就是将属于同一个文件系统的操作的个数设置为0。 log 的基本工作方式。\nLog write Commit op Install log Clean log 假设我们 crash 并重启了。在重启的时候，文件系统会查看 log 的 commit 记录值，如果是0的话，那么什么也不做。如果大于0的话，我们就知道 log 中存储的 block 需要被写入到文件系统中，很明显我们在 crash 的时候并不一定完成了 install log，我们可能是在 commit 之后，clean log 之前 crash 的。所以这个时候我们需要做的就是 reinstall（注，也就是将 log 中的 block 再次写入到文件系统），再 clean log。 接下来看看 XV6 中的 log 结构：\n1 2 3 4 5 6 7 8 9 struct log { struct spinlock lock; int start; int size; int outstanding; // how many FS sys calls are executing. int committing; // in commit(), please wait. int dev; struct logheader lh; }; 这里有一个 logheader 其实就是 log block 的 head ，长这样的：\n1 2 3 4 struct logheader { int n; // 数字n代表有效的log block的数量 int block[LOGSIZE]; // 每个log block的实际对应的block编号 如 45、33 }; 最后看看怎么使用 log 在系统调用中一个典型的 log 使用就像这样：\n1 2 3 4 5 6 7 begin_op(); ... bp = bread(...); bp-\u0026gt;data[...] = ...; log_write(bp); ... end_op(); 一个事务transaction 以 begin_op 表示开始和 end_op 表示结束。并且其中的事务所有写 block 操作具备原子性，这意味着这些写 block 操作要么全写入，要么全不写入。 在 begin_op 和 end_op 之间，磁盘上或者内存中的数据结构会更新。但是在 end_op 之前，并不会有实际的改变（也就是不会写入到实际的 block 中）。在 end_op 时，我们会将数据写入到 log 中，之后再写入 commit record 或者 log header。这里有趣的是，当文件系统调用执行写磁盘时会发生什么？ log_write 是由文件系统的 logging 实现的方法。任何一个文件系统调用的 begin_op 和 end_op 之间的写操作总是会走到 log_write。log_write 函数位于log.c 文件。其中，文件系统中的所有 bwrite 都需要被 log_write 替换\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 void log_write(struct buf *b) { int i; acquire(\u0026amp;log.lock); if (log.lh.n \u0026gt;= LOGSIZE || log.lh.n \u0026gt;= log.size - 1) panic(\u0026#34;too big a transaction\u0026#34;); if (log.outstanding \u0026lt; 1) panic(\u0026#34;log_write outside of trans\u0026#34;); for (i = 0; i \u0026lt; log.lh.n; i++) { if (log.lh.block[i] == b-\u0026gt;blockno) // log absorption break; } log.lh.block[i] = b-\u0026gt;blockno; if (i == log.lh.n) { // Add new block to log? bpin(b); log.lh.n++; } printf(\u0026#34;log_write: blockno: %d\\n\u0026#34;, b-\u0026gt;blockno); // printf(\u0026#34;log_write: log.lh.n: %d\\n\u0026#34;, log.lh.n); // printf(\u0026#34;log_write: log.committing: %d\\n\u0026#34;, log.committing); release(\u0026amp;log.lock); } 接下来看一下发生在 XV6 的启动过程中的文件系统的恢复流程。当系统 crash 并重启了，在 XV6启动过程中做的一件事情就是调用 initlog 函数。\n1 2 3 4 5 6 7 8 9 10 11 12 void initlog(int dev, struct superblock *sb) { if (sizeof(struct logheader) \u0026gt;= BSIZE) panic(\u0026#34;initlog: too big logheader\u0026#34;); initlock(\u0026amp;log.lock, \u0026#34;log\u0026#34;); log.start = sb-\u0026gt;logstart; log.size = sb-\u0026gt;nlog; log.dev = dev; recover_from_log(); } 1 2 3 4 5 6 7 8 static void recover_from_log(void) { read_head(); install_trans(1); // if committed, copy from log to disk log.lh.n = 0; write_head(); // clear the log } recover_from_log 先调用 read_head 函数从磁盘中读取 header，之后调用 install_trans 函数。这个函数之前在 commit 函数中也调用过，它就是读取 log header 中的 n，然后根据 n 将所有的 log block 拷贝到文件系统的 block 中。recover_from_log 在最后也会跟之前一样清除 log。\n这就是恢复的全部流程。如果我们在 install_trans 函数中又 crash 了，也不会有问题，因为之后再重启时，XV6会再次调用 initlog 函数，再调用 recover_from_log 来重新 install log。如果我们在 commit 之前 crash 了多次，在最终成功 commit 时，log 可能会 install 多次。\n（其他问题暂定）\nlog 和 cache 的区别\nLog（日志）：日志是用于记录系统运行状态、事件和操作的记录。它通常用于故障排查、监控系统运行情况以及追踪用户操作等方面。日志文件可以包含系统错误、警告、信息等不同级别的记录，有助于系统管理员或开发人员了解系统的运行状况 Cache（缓存）：缓存是一种高速数据存储层，用于临时存储数据，通常是暂时性的。缓存被用来存储最近或频繁访问的数据，以提高数据访问速度。它是一种小型、更快速、更昂贵的内存，用于改善最近或频繁访问的数据的性能。缓存通常被CPU、应用程序、Web浏览器和操作系统使用，以减少数据访问时间、降低延迟并改善输入/输出性能 索引结点 （Inode） 目录 （Directory） 路径名 （Pathname） ","date":"2024-03-10T16:37:33+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/xv6%E7%9A%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","title":"XV6的文件系统"},{"content":" 看我影分身\n我将进程和线程放在一起写就是因为它们两个是表兄弟 ，这两个东东可以说是我不好区分的事，在之前我利用 AI 来尝试理解\u0026mdash; [[进程（Process）和 线程（Thread）]] \u0026mdash; 过于笼统，因此我要自己通过 XV6 来理解。\n进程 进程是对于计算机中运行的程序的对象。它包括了程序的代码、数据、执行状态以及系统资源的拷贝，如内存空间、文件等。\n操作系统通过对进程的管理来具象的调度程序，进程也对于将 User Space 和 Kernel Space 有隔离提供帮助，如，内存的虚拟 \u0026mdash; 每个进程有自己的页表。如果把 CPU 看成一个巨大的工厂，那么进程在其中充当的是某产品的完整生产路径，它拥有许多的工人、原料、某流水线、打包等。而其中它与其它产品没关系（至少没有直接关系）。\n一个进程需要的空间\n对于操作系统来说进程就是数据结构，看看在 XV6 中的 proc.h\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // Per-process state struct proc { struct spinlock lock; // p-\u0026gt;lock must be held when using these: enum procstate state; // Process state void *chan; // If non-zero, sleeping on chan int killed; // If non-zero, have been killed int xstate; // Exit status to be returned to parent\u0026#39;s wait int pid; // Process ID // wait_lock must be held when using this: struct proc *parent; // Parent process // these are private to the process, so p-\u0026gt;lock need not be held. uint64 kstack; // Virtual address of kernel stack uint64 sz; // Size of process memory (bytes) pagetable_t pagetable; // User page table struct trapframe *trapframe; // data page for trampoline.S struct context context; // swtch() here to run process struct file *ofile[NOFILE]; // Open files struct inode *cwd; // Current directory char name[16]; // Process name (debugging) }; 很复杂，在真正的系统中会更加的复杂和多样。\n其中，enum procstate state; 进程的状态（有些是线程的）\n1 enum procstate { UNUSED, USED, SLEEPING, RUNNABLE, RUNNING, ZOMBIE }; 简单讲有以下几种：\n运行（running）：在运行状态下，进程正在处理器上运行。这意味着它正在执行指令。 就绪（ready）：在就绪状态下，进程已准备好运行，但由于某种原因，操作系统选择不在此时运行。 阻塞（blocked）：在阻塞状态下，一个进程执行了某种操作，直到发生其他事件时才会准备运行。一个常见的例子是，当进程向磁盘发起 I/O 请求时，它会被阻塞，因此其他进程可以使用处理器。 还有一个特殊的： ZOMBIE （僵尸）： \u0026ldquo;僵尸状态\u0026quot;是指一个进程已经终止执行，但其父进程尚未对其进行善后处理，导致其在进程表中仍然保留着。这种状态下的进程被称为\u0026quot;僵尸进程\u0026rdquo;。僵尸进程不再执行任何指令，但其进程表项仍然占用系统资源。通常情况下，父进程应该调用 wait() 或 waitpid() 函数来回收僵尸进程，释放其占用的资源。 1 2 3 4 void *chan; // If non-zero, sleeping on chan int killed; // If non-zero, have been killed int xstate; // Exit status to be returned to parent\u0026#39;s wait int pid; // Process ID 这些都是进程的属性。\n1 struct proc *parent; // Parent process 在 fork() 中可能会有父进程。init 进程是所有进程的 parent\n1 2 3 4 5 6 7 8 9 // these are private to the process, so p-\u0026gt;lock need not be held. uint64 kstack; // Virtual address of kernel stack uint64 sz; // Size of process memory (bytes) pagetable_t pagetable; // User page table struct trapframe *trapframe; // data page for trampoline.S struct context context; // swtch() here to run process struct file *ofile[NOFILE]; // Open files struct inode *cwd; // Current directory char name[16]; // Process name (debugging) 这些就是在系统中可以怎么做产品的具体原料、流水线了。\n但是我们在 CPU 中不是一直做一个进程的，进程间需要交换而进程之间的交换就是线程之间的交换 。\n线程 线程可以认为是一种在有多个任务时简化编程的抽象。一个线程可以认为是串行执行代码的单元。如果你写了一个程序只是按顺序执行代码，那么你可以认为这个程序就是个单线程程序，这是对于线程的一种宽松的定义。虽然人们对于线程有很多不同的定义，在这里，我们认为线程就是单个串行执行代码的单元，它只占用一个 CPU 并且以普通的方式一个接一个的执行指令。\n再次来到我的工厂里面，如果进程完整生产路径，那么线程就是这条路径上的最小单位 \u0026mdash; 一条流水线的工作\u0026mdash; 有相应的属性。这里其实我把 RISC-V 里面的流水线结构用上了，想想看一条流水线上有一个线程在运行，所以我叫它\u0026mdash;流水线的工作。\n值得一提的，我们可以随时保存线程的属性并暂停线程的运行，并在之后通过恢复属性来恢复线程的运行。线程的属性包含了三个部分：\n程序计数器（Program Counter），它表示当前线程执行指令的位置。 保存变量的寄存器。 程序的 Stack。通常来说每个线程都有属于自己的 Stack，Stack 记录了函数调用的记录，并反映了当前线程的执行点。 线程是用来实现多进程的并行运行的具体，我们为了提高速率就让进程可以不停止的运动，因此就把线程用来执行分时复用的任务，有一个进程停了就切换另一个。\n而让线程可以的并行运行主要有两个策略：\n第一个策略，在多核处理器上使用多个 CPU，每个 CPU 都可以运行一个线程。如果你有4个 CPU，那么每个 CPU 可以运行一个线程。每个线程自动的根据所在 CPU 就有了程序计数器和寄存器。但是如果你只有4个 CPU，却有上千个线程，每个 CPU 只运行一个线程就不能解决这里的问题了。 第二个策略，让一个 CPU 在多个线程之间来回切换。假设我只有一个 CPU，但是有1000个线程，先运行一个线程，之后将线程的状态保存，再切换至运行第二个线程，然后再是第三个线程，依次类推直到每个线程都运行了一会，再回来重新执行第一个线程。 我的 cpu 就 8 核，但有六千多的 Threads。\n那么这里有一个问题，一个进程可以有多少线程？\n在 XV6 中一个进程有两个线程：\nUser Thread： 每一个用户进程都有独立的内存地址空间，并且包含了一个线程，这个线程控制了用户进程代码指令的执行。 Kernel Thread ： 对于每个用户进程都有一个内核线程来执行来自用户进程的系统调用。所有的内核线程都共享了内核内存，所以XV6的内核线程的确会共享内存。 如果 XV 6 内核决定从一个用户进程切换到另一个用户进程，那么首先在内核中第一个进程的内核线程会被切换到第二个进程的内核线程。之后再在第二个进程的内核线程中返回到用户空间的第二个进程，这里返回也是通过恢复 trapframe 中保存的用户进程状态完成。\n这里核心点在于，在 XV6中，任何时候都需要经历：\n从一个用户进程切换到另一个用户进程，都需要从第一个用户进程接入到内核中，保存用户进程的状态并运行第一个用户进程的内核线程。 再从第一个用户进程的内核线程切换到第二个用户进程的内核线程。 之后，第二个用户进程的内核线程暂停自己，并恢复第二个用户进程的用户寄存器。 最后返回到第二个用户进程继续执行。 通常说的是从一个线程切换到另一个线程，因为在切换的过程中需要先保存前一个线程的寄存器，然后再恢复之前保存的最后一个线程的寄存器。\n线程状态 RUNNING，线程当前正在某个CPU上运行 RUNABLE，线程还没有在某个CPU上运行，但是一旦有空闲的CPU就可以运行 SLEEPING，这个状态意味着线程在等待一些 I/O 事件，它只会在 I/O 事件发生了之后运行 这里不同的线程是由状态区分，但是实际上线程的完整状态会要复杂的多。\nXV6 线程切换 实际上的线程切换顺序更像这样：\n一个进程出于某种原因想要进入休眠状态，比如说出让 CPU 或者等待据，它会先获取自己的锁； 之后进程将自己的状态从 RUNNING 设置为 RUNNABLE； 之后进程调用 switch 函数，其实是调用 sched 函数在 sched 函数中再调用的 switch 函数； switch 函数将当前的线程切换到调度器线程； 调度器线程之前也调用了 switch 函数，现在恢复执行会从自己的 switch 函数返回； 返回之后，调度器线程会释放刚刚出让了 CPU 的进程的锁 接下来我们以 CPU 作为一个参照物来理解线程切换，现在带着几个问题：\n线程为什么切换？ 线程是怎么切换？ 线程切换要保存什么？ 开始 假设我们有两个 CPU \u0026mdash; CPU0、CPU1，CPU0 正在运行一个进程——shell ——这个用户程序在运行时，实际上是其中的用户线程在运行，此时我想运行另一个进程\u0026mdash;ls ，CPU0 会进入 trap —— 通过系统调用、定时器中断、I/O 中断 —— 同时属于这个用户程序的内核线程被激活，CPU0 使用来自内核线程的stack，而现在如果 XV6内核决定从一个用户进程切换到另一个用户进程，那么首先在内核中第一个进程的内核线程会被切换到第二个进程的内核线程。\n而在 xv6 的代码实现中（用定时器中断举例），我会进入 yield() 函数，是一个放弃当前 CPU 的函数\n1 2 3 4 5 6 7 8 9 10 // Give up the CPU for one scheduling round. void yield(void) { struct proc *p = myproc(); acquire(\u0026amp;p-\u0026gt;lock); p-\u0026gt;state = RUNNABLE; sched(); release(\u0026amp;p-\u0026gt;lock); } 进入到 yield() 后取得当前进程的锁也就是shell 改变它的状态为RUNNABLE ，这里有个奇怪的地方，我们不是在对线程改状态吗，为什么是改变了进程的状态？ 我个人认为这是因为在 xv6 中一个进程只有一个用户线程，所以就把线程的状态放在进程里面。然后最重要的线程调度来了。\nsched () 函数实际上就是将一个 RUNNING 线程转换成一个 RUNNABLE 线程的过程。所以对于每一个 RUNNABLE 线程，当我们将它从 RUNNING 转变成 RUNABLE 时，我们需要将之前位于 CPU0 的信息也就是 PC 和寄存器拷贝到内存中的某个位置，注意这里不是从内存中的某处进行拷贝，而是从 CPU 中的寄存器拷贝。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 void sched(void) { int intena; struct proc *p = myproc(); if(!holding(\u0026amp;p-\u0026gt;lock)) panic(\u0026#34;sched p-\u0026gt;lock\u0026#34;); if(mycpu()-\u0026gt;noff != 1) panic(\u0026#34;sched locks\u0026#34;); if(p-\u0026gt;state == RUNNING) panic(\u0026#34;sched running\u0026#34;); if(intr_get()) panic(\u0026#34;sched interruptible\u0026#34;); intena = mycpu()-\u0026gt;intena; swtch(\u0026amp;p-\u0026gt;context, \u0026amp;mycpu()-\u0026gt;context); mycpu()-\u0026gt;intena = intena; } 可以发现，sched 函数只是做了一些合理性检查，如果发现异常就 panic。我们直接走到位于底部的 swtch 函数。这个函数是线程调度的核心。\nswtch 函数有两个参数，一个是将被保存的PC 和callee 寄存器 的地址，另一个是将恢复的 PC 和callee 寄存器 的地址。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 swtch: sd ra, 0(a0) sd sp, 8(a0) sd s0, 16(a0) sd s1, 24(a0) sd s2, 32(a0) sd s3, 40(a0) sd s4, 48(a0) sd s5, 56(a0) sd s6, 64(a0) sd s7, 72(a0) sd s8, 80(a0) sd s9, 88(a0) sd s10, 96(a0) sd s11, 104(a0) ld ra, 0(a1) ld sp, 8(a1) ld s0, 16(a1) ld s1, 24(a1) ld s2, 32(a1) ld s3, 40(a1) ld s4, 48(a1) ld s5, 56(a1) ld s6, 64(a1) ld s7, 72(a1) ld s8, 80(a1) ld s9, 88(a1) ld s10, 96(a1) ld s11, 104(a1) ret 你会发现没有 PC 啊，你是不是写错了。停，真正好玩的地方出现了。让我们想想在 CPU 的流水线中 PC 是做什么的，对他就是一个指标，PC 指哪里的地址我们的 CPU 就做什么操作，寄存器真是\u0026quot;呆呆的\u0026quot;，因为我只要改变了 PC 的值 CPU 不管和之前的相不相关，它都\u0026quot;呆呆的\u0026quot;去执行，而我们是不是调用了 swtch 函数，那么就是说 PC -\u0026gt; swtch 指向地址，那么 RA \u0026lt;- PC + 4 ra 寄存器 是保存了 swtch 函数的返回地址即下一句 mycpu()-\u0026gt;intena = intena; 这是我保存的寄存器，那恢复的寄存器中 RA 是不是就是另一个 PC ，之后我返回 swtch 函数 PC 的值更新为恢复的 RA 0(a1)的值。我写到这个不得不佩服发现这个的天才啊。\n问题：为什么 RISC-V 中有32个寄存器，但是 swtch 函数中只保存并恢复了14个（callee）寄存器？ 因为 swtch 是按照一个普通函数来调用的，对于有些寄存器，swtch 函数的调用者（sched）默认 swtch 函数会做修改，所以调用者已经在自己的栈上保存了这些寄存器，当函数返回时，这些寄存器会自动恢复。所以 swtch 函数里只需要保存 Callee Saved Register 就行。\n最后是sp（Stack Pointer）寄存器。它实际是当前进程的内核栈地址，它由虚拟内存系统映射在了一个高地址。\n问题：为什么我们恢复的是来自 CPU 调度器线程的 context 对象 \u0026amp;mycpu()-\u0026gt;context 中的内容？ 因为在之前 ls 程序的内核线程对应的内核寄存器也已经保存在对应的 context 对象中，即 CPU 0 中的 context 。\n一旦 swtch 返回，那么现在PC指向了 scheduler 函数，因为这是我们恢复了调度器线程的 context 对象中的内容。\n调度器线程 scheduler 函数，Per-CPU 进程调度程序对于每个 CPU 在设置好自己之后都要调用 scheduler()。就是将一个 RUNNABLE 线程转换成一个 RUNNING 线程的过程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 void scheduler(void) { struct proc *p; struct cpu *c = mycpu(); c-\u0026gt;proc = 0; for(;;){ // Avoid deadlock by ensuring that devices can interrupt. intr_on(); for(p = proc; p \u0026lt; \u0026amp;proc[NPROC]; p++) { acquire(\u0026amp;p-\u0026gt;lock); if(p-\u0026gt;state == RUNNABLE) { // Switch to chosen process. It is the process\u0026#39;s job // to release its lock and then reacquire it // before jumping back to us. p-\u0026gt;state = RUNNING; c-\u0026gt;proc = p; swtch(\u0026amp;c-\u0026gt;context, \u0026amp;p-\u0026gt;context); // Process is done running for now. // It should have changed its p-\u0026gt;state before coming back. c-\u0026gt;proc = 0; } release(\u0026amp;p-\u0026gt;lock); } } } 其实可以猜猜我现在的 PC 指那里，对，指向 c-\u0026gt;proc = 0;，进行设置现在并没有在这个 CPU0 核上运行的进程。之前在 yield 函数中获取了进程的锁，因为 yield 不想在进程完全进入到 Sleep 状态之前，有任何其他的 CPU 核的调度器线程看到这个进程并运行它。而现在我们做完了，所以现在可以释放锁了（蛮远的）。ok，现在 CPU0 为空了，它可以去找其他的为 RUNNABLE 的进程了，回到一开始还记得我们有两个 CPU 吗？我们一直没用到 CPU1 ，现在你应该知道它要做什么了，它一直在 scheduler 中找适合的进程，你看，我们之前把 shell 进程 RUNNABLE 了，CPU1 可以去执行它了。而我的 CPU0 可能去执行 ls 了。\n问题：如果不是因为定时器中断发生的切换，我们是不是可以期望 ra 寄存器指向其他位置，例如 sleep 函数？ Robert 教授：是的，我们之前看到了代码执行到这里会包含一些系统调用相关的函数。你基本上回答了自己的问题，如果我们因为定时器中断之外的原因而停止了执行当前的进程，switch 会返回到一些系统调用的代码中，而不是我们这里看到 sched 函数。我记得 sleep 最后也调用了 sched 函数，虽然 bracktrace 可能看起来会不一样，但是还是会包含 sched。所以我这里只介绍了一种进程间切换的方法，也就是因为定时器中断而发生切换。但是还有其他的可能会触发进程切换，例如等待 I/O 或者等待另一个进程向 pipe 写数据。\n线程除了寄存器以外的还有很多其他状态，它还有变量，堆中的数据等等，但是所有的这些数据都在内存中，并且会保持不变。我们没有改变线程的任何栈或者堆数据。所以线程切换的过程中，处理器中的寄存器是唯一的不稳定状态，且需要保存并恢复。而所有其他在内存中的数据会保存在内存中不被改变，所以不用特意保存并恢复。我们只是保存并恢复了处理器中的寄存器，因为我们想在新的线程中也使用相同的一组寄存器。我认为不改变其他状态是因为 CPU 之间也是内核线程之间是共享内存的。\n","date":"2024-03-10T16:37:08+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/xv6%E7%9A%84%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/","title":"XV6的进程和线程"},{"content":" 性能快 -\u0026gt; 性能慢\n硬件的提升 其实早在 21 世纪初的时候 CPU 的单核的性能可以说到达了一个瓶颈，单个 CPU 已经不可以满足需求了，计算机科学家们需要找一个突破瓶颈的方法。我们的需求是什么，要更加快速的性能和计算能力，有一个比较：如果强行给一个 CPU 提升性能，那么它的功耗也是增加的而且加得很多，但新加入一个 CPU 不仅仅提升了性能，而且功耗增加在接受范围，因此，多核的时代来临了。\n为什么要使用锁 首先，为什么在多核系统中我们需要锁？锁又是什么东西？这要从应用程序想要使用多个 CPU 核开始。我们知道使用多个 CPU 核可以带来性能的提升，如果一个应用程序运行在多个 CPU 核上，并且执行了系统调用，那么内核需要能够处理并行的系统调用。如果系统调用以并行的方式运行在多个 CPU 核上，那么它们可能会并行的访问内核中共享的数据结构或是数据。当并行的访问数据结构时，例如：一个核在读取数据，另一个核在写入数据，我们需要使用锁来协调对于共享数据的更新，以确保数据的一致性。所以，我们需要锁来控制并确保共享的数据是正确的。\n但是实际的情况有些令人失望，因为我们想要通过并行来获得高性能，我们想要并行的在不同的 CPU 核上执行系统调用，但是如果这些系统调用使用了共享的数据，我们又需要使用锁，而锁又会使得这些系统调用串行执行，所以最后锁反过来又限制了性能。\n所以现在我们处于一个矛盾的处境，出于正确性，我们需要使用锁，但是考虑到性能，锁又是极不好的。这就是我说的 性能越快 -\u0026gt; 性能越慢 。\n首先，我们需要了解一下锁用在哪里？前面说锁是控制并确保共享的数据 的 标志 。这个数据是什么？其实说锁像标志不如像一个仓库管理员，一旦有人来改变仓库的东西都要 他 出面管理防止出问题。\n来看 xv6 中的 kfree() :\n1 2 3 4 acquire(\u0026amp;kmem.lock) r-\u0026gt;next = kmem.freelist; kmem.freelist = r; release(\u0026amp;kmem.lock) 其中，在锁的 acquire 和 release 之间的代码，通常被称为critical section。它就是我们要管理的数据\n为了确保数据的正确性，我们用锁来管理 critical section 区。当一份共享数据同时被读写时，如果没有锁的话，可能会出现 race condition （竞争条件），进而导致程序出错。如：在 r-\u0026gt;next = kmem.freelist; 中 CPU0 和 CPU1 同时进行，那么 r-\u0026gt;next 可能指向的是 CPU0 的数据，也可能是 CPU1 的数据，这里会出现使我们不愿意看到的巨大错误。\nrace condition 是比较讨厌的，值得一提的是 race condition 可以有不同的表现形式，并且它可能发生，也可能不发生。我们不希望发生。\n接下来让就具体的介绍一下锁。锁就是一个对象，就像其他在内核中的对象一样。有一个结构体叫做lock，它包含了一些字段，这些字段中维护了锁的状态。锁有非常直观的 API：\nacquire，接收指向 lock 的指针作为参数。acquire 确保了在任何时间，只会有一个进程能够成功的获取锁。 release，也接收指向 lock 的指针作为参数。在同一时间尝试获取锁的其他进程需要等待，直到持有锁的进程对锁调用 release。 所以，用锁来避免数据结构的资源竞争（race condition）和保护资源。\n什么时候使用锁 在使用锁之前要了解一个机制 \u0026mdash; 原子操作（atomic operation）。 简单来讲，一般在程序中 i+=1 有三个动作：\n1 2 3 ld t0, 0(a0) addi t0, t0, 1 sd t0, 0(a0) 原子操作就是把这三个操作由一个操作完成。\n而之前的被保护的数据之所以被称为 critical section，是因为通常会在这里以原子的方式执行共享数据的更新。所以基本上来说，如果在 acquire 和 release 之间有多条指令，它们要么会一起执行，要么一条也不会执行。所以（CPU）永远也不可能看到位于 critical section 中的具体代码，反之，在 race condition 中多个 CPU 在 critical section 区上交织的执行。所以这样就能避免 race condition。\n现在的程序通常会有许多锁。实际上，XV6中就有很多的锁。为什么会有这么多锁呢？因为锁序列化了代码的执行。如果两个处理器想要进入到同一个 critical section 中，只会有一个能成功进入，另一个处理器会在第一个处理器从 critical section 中退出之后再进入。所以这里以串行执行完全没有并行执行。\n如果让内核中只有一把大锁，我们暂时将之称为 big kernel lock。基本上所有的系统调用都会被这把大锁保护而被序列化。系统调用会按照这样的流程处理：一个系统调用获取到了 big kernel lock，完成自己的操作，之后释放这个 big kernel lock，再返回到用户空间，之后下一个系统调用才能执行。这样的话，如果我们有一个应用程序并行的调用多个系统调用，这些系统调用会串行的执行，因为我们只有一把锁。所以通常来说，例如 XV6的操作系统会有多把锁，这样就能获得某种程度的并发执行。如果两个系统调用使用了两把不同的锁，那么它们就能完全的并行运行。\n很明显，锁限制了并发性，也限制了性能。没有很好的规则来规定锁的使用。如：如果两个进程访问了一个共享的数据结构，并且其中一个进程会更新共享的数据结构，那么就需要对于这个共享的数据结构加锁。 矛盾的是，有时候这个规则太过严格，而有时候这个规则又太过宽松了。除了共享的数据，在一些其他场合也需要锁，例如对于 printf，如果我们将一个字符串传递给它，XV6会尝试原子性的将整个字符串输出，而不是与其他进程的 printf 交织输出。尽管这里没有共享的数据结构，但在这里锁仍然很有用处，因为我们想要 printf 的输出也是序列化的。\n因此，锁应该与操作而不是数据关联，和操作的顺序相关。\n锁的特性和死锁 锁可以避免丢失更新。如果你回想我们之前在 kalloc.c 中的例子，丢失更新是指我们丢失了对于某个内存 page 在 kfree 函数中的更新。如果没有锁，在出现 race condition 的时候，内存 page 不会被加到 freelist 中。但是加上锁之后，我们就不会丢失这里的更新。 锁可以让操作具有原子性。我们之前介绍了加锁解锁之间的区域是 critical section，在 critical section 的所有操作会都会作为一个原子操作执行。 锁可以维护共享数据结构的**不变性**。共享数据结构如果不被任何进程修改的话是会保持不变的。如果某个进程acquire了锁并且做了一些更新操作，共享数据的不变性暂时会被破坏，但是在release锁之后，数据的不变性又恢复了。 数据结构的不变性是在不同的 CPU 中相对的，比如：CPU0 改变了某数据结构对它而言是变化的，但对于 CPU1 看到的就是不变的\n死锁（Deadlock），在用锁的时候经常遇到，一个死锁的最简单的场景就是：首先 acquire 一个锁，然后进入到 critical section；在 critical section 中，再 acquire 同一个锁；第二个 acquire 必须要等到第一个 acquire 状态被 release 了才能继续执行，但是不继续执行的话又走不到第一个 release，所以程序就一直卡在这了。这就是一个死锁。让我想起著名的哲學家就餐問題。还有一个现实场景：堵车。\n死锁的解决方案是：如果你有多个锁，你需要对锁进行排序，所有的操作都必须以相同的顺序获取锁。然后以相同的顺序丢弃锁。\n锁与性能 我们想要获得更好的性能，那么我们需要有更多的锁，但是这又引入了大量的工作。\n通常来说，开发的流程是：\n先以coarse-grained lock（大锁）开始。 再对程序进行测试，来看一下程序是否能使用多核。 如果可以的话，那么工作就结束了，你对于锁的设计足够好了；如果不可以的话，那意味着锁存在竞争，多个进程会尝试获取同一个锁，因此它们将会序列化的执行，性能也上不去，之后你就需要重构程序。 在这个流程中，测试的过程比较重要。有可能模块使用了coarse-grained lock，但是它并没有经常被并行的调用，那么其实就没有必要重构程序，因为重构程序设计到大量的工作，并且也会使得代码变得复杂。所以如果不是必要的话，还是不要进行重构。\n实现锁 我在这里有具体的笔记。 一定要注意的点是： !!! 不要把锁变成 critical section 区 !!! !!! 不要把锁变成 critical section 区 !!! !!! 不要把锁变成 critical section 区 !!!\n所以 spinlock 需要处理两类并发，一类是不同 CPU 之间的并发，一类是相同 CPU 上中断和普通程序之间的并发 我们需要在 acquire 中关闭中断。\nSleep \u0026amp; Wakeup Sleep 函数中最后一件事情就是重新获取 condition lock。\n总结 硬件性能瓶颈是指当单个 CPU 核的性能已经不能满足应用程序的需求时，计算机科学家们需要寻找突破瓶颈的方法。多核系统中的锁用于控制并确保共享数据的更新，以确保数据的一致性。然而，锁也会限制性能，因为它会使得系统调用串行执行。为了解决这个问题，我们可以考虑使用更多的锁，以便在某种程度上获得并发执行。但是，这会引入大量的工作，因此需要对锁的设计和使用进行充分考虑。\n在实际应用中，我们可以通过测试程序来判断是否需要重构锁的设计，如果程序可以并行执行，那么锁的设计可能足够好；如果不能，那么需要对锁进行重构，以提高并发性能。\n总之，硬件性能瓶颈推动了计算机科学家们寻找突破方法，而锁是一种解决共享数据竞争的方法。然而，锁也会限制性能，因此需要在设计和使用中进行充分考虑。\n使用锁的原因主要有以下几点：\n保证资源共享性：当多个线程同时访问共享资源时，使用锁可以确保资源在同一时间只被一个线程访问，从而避免资源不同步和错误。 避免资源竞争：当多个线程同时访问共享资源时，可能导致资源竞争，导致未预期的结果。使用锁可以避免资源竞争，确保资源的正确使用。 提高代码可重用性：使用锁可以将多线程访问的代码封装成一个线程安全的单元，从而提高代码的可重用性。 降低开发难度：使用锁可以简化编程者需要关注的事物，降低开发难度。 保证线程安全：使用锁可以确保程序中的线程安全问题，避免因线程不安全导致的错误和异常。 ","date":"2024-03-10T16:36:19+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/xv6%E7%9A%84%E9%94%81%E5%92%8C%E5%B9%B6%E8%A1%8C/","title":"XV6的锁和并行"},{"content":" ls 去哪里了\n中断硬件 中断对应的场景很简单，就是硬件（外设）想要得到操作系统的关注。当硬件设备需要处理器的注意时，它会发送一个中断信号，这会导致处理器中断当前正在执行的任务，保存当前状态，并开始执行一个称为中断处理程序（interrupt handler）的特殊程序。中断处理程序会处理中断事件，然后恢复之前的任务状态，使得处理器可以继续执行被中断的任务。\n像系统调用，但有几点不一样：\n异步 (asynchronous)：在硬件中断中 interrupt handler 并不在进程的 context 下，所以 cpu 是异步的。 并发 (concurrency)：对于中断来说，CPU 和生成中断的设备是并行的在运行。 程序设备 (program device) ：要为用到的硬件依据相关的文档编程。 程序设备地址 mapping kernel 设备都连接到处理器上，处理器上是通过 Platform Level Interrupt Control，简称 PLIC 来处理设备中断。 PLIC 会路由（像收费站）这些中断，提醒 CPU 有中断，有空的 CPU 核会 Claim 中断，之后接收、处理中断，提醒 PLIC 。\n设备驱动 设备驱动是一种软件，用于允许操作系统与计算机硬件进行通信和交互。简单的讲：管理设备的代码称为驱动且所有的驱动都在内核中。\n大部分驱动都分为两个部分：\n驱动程序（bottom）：驱动程序负责设备的控制和管理，包括设备的初始化、数据传输、状态监控等。驱动程序通常是由内核编写，并且运行在内核模式下，具有较高的权限。 设备程序（top）：设备设置程序通常是用户空间程序，用于配置和控制设备。这些程序通常不运行在内核模式下，具有较低的权限。设备设置程序可以通过系统调用与驱动程序进行交互，实现对设备的控制和管理。 这种分层结构进行了隔离，两者的交互通过之间的队列 来实现。\n如何对设备进行编程。通常来说，编程是通过 memory mapped I/O 完成的。在一开始的时候，设备地址就规定出现在物理地址的特定区间内。在通过 load / store 指令就可以读写设备的控制寄存器。\nXV6 中断例子 当XV6启动时，Shell会输出提示符“$ ”，如果我们在键盘上输入ls，最终可以看到“$ ls”。我们接下来通过研究Console是如何显示出“$ ls”，来看一下设备中断是如何工作的。\n实际上“$ ”和“ls”还不太一样，“$ ”是Shell程序的输出，而“ls”是用户通过键盘输入之后再显示出来的。\nRISC-V 有许多与中断相关的寄存器：\nSIE（Supervisor Interrupt Enable）寄存器。这个寄存器中有一个bit（E）专门针对例如UART的外部设备的中断；有一个bit（S）专门针对软件中断，软件中断可能由一个CPU核触发给另一个CPU核；还有一个bit（T）专门针对定时器中断。我们这节课只关注外部设备的中断。\nSSTATUS（Supervisor Status）寄存器。这个寄存器中有一个bit来打开或者关闭中断。每一个CPU核都有独立的SIE和SSTATUS寄存器，除了通过SIE寄存器来单独控制特定的中断，还可以通过SSTATUS寄存器中的一个bit来控制所有的中断。\nSIP（Supervisor Interrupt Pending）寄存器。当发生中断时，处理器可以通过查看这个寄存器知道当前是什么类型的中断。\nSCAUSE寄存器，这个寄存器我们之前看过很多次。它会表明当前状态的原因是中断。\nSTVEC 寄存器，它会保存当 trap，page fault 或者中断发生时，CPU 运行的用户程序的程序计数器，这样才能在稍后恢复程序的运行。\n这里首先初始化了锁，我们现在还不关心这个锁。然后调用了 uartinit，uartinit 函数位于 uart.c 文件。这个函数实际上就是配置好 UART 芯片使其可以被使用。\n这里的流程是先关闭中断，之后设置波特率，设置字符长度为8bit，重置FIFO，最后再重新打开中断。\n对于其中的 WriteReg(IER, 0x00) 就是把 0x00 写入到 IER register, 下同\nUART 中的寄存器\n运行完这个函数之后，原则上UART就可以生成中断了。但是因为我们还没有对PLIC编程，所以中断不能被CPU感知。最终，在main函数中，需要调用plicinit函数。\n1 2 3 4 5 6 7 void plicinit(void) { // set desired IRQ priorities non-zero (otherwise disabled). *(uint32*)(PLIC + UART0_IRQ*4) = 1; // 0x0c000000L + 10*4 *(uint32*)(PLIC + VIRTIO0_IRQ*4) = 1; // 0x0c000000L + 1*4 } 第一句是：设置 PLIC 会接收来自 UART 的中断 第二句是：设置 PLIC 会接收来自 IO磁盘 的中断\nmain 函数中，plicinit 之后就是 plicinithart 函数。plicinit 是由0号 CPU 运行，之后，每个 CPU 的核都需要调用 plicinithart 函数表明对于哪些外设中断感兴趣。所以在 plicinithart 函数中，每个 CPU 的核都表明自己对来自于 UART 和 VIRTIO 的中断感兴趣。因为我们忽略中断的优先级，所以我们将优先级设置为0。\n1 2 3 4 5 6 7 8 9 10 void plicinithart(void) { int hart = cpuid(); // set uart\u0026#39;s enable bit for this hart\u0026#39;s S-mode. *(uint32*)PLIC_SENABLE(hart)= (1 \u0026lt;\u0026lt; UART0_IRQ) | (1 \u0026lt;\u0026lt; VIRTIO0_IRQ); // set this hart\u0026#39;s S-mode priority threshold to 0. *(uint32*)PLIC_SPRIORITY(hart) = 0; } 到目前为止，我们有了生成中断的外部设备，我们有了 PLIC 可以传递中断到单个的 CPU。但是 CPU 自己还没有设置好接收中断，因为我们还没有设置好 SSTATUS 寄存器。 在 main 函数的最后，程序调用了 scheduler 函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 void scheduler(void) { struct proc *p; struct cpu *c = mycpu(); c-\u0026gt;proc = 0; for(;;){ // Avoid deadlock by ensuring that devices can interrupt. intr_on(); // for(p = proc; p \u0026lt; \u0026amp;proc[NPROC]; p++) { acquire(\u0026amp;p-\u0026gt;lock); if(p-\u0026gt;state == RUNNABLE) { // Switch to chosen process. It is the process\u0026#39;s job // to release its lock and then reacquire it // before jumping back to us. p-\u0026gt;state = RUNNING; c-\u0026gt;proc = p; swtch(\u0026amp;c-\u0026gt;context, \u0026amp;p-\u0026gt;context); // Process is done running for now. // It should have changed its p-\u0026gt;state before coming back. c-\u0026gt;proc = 0; } release(\u0026amp;p-\u0026gt;lock); } } } 来自 Shell 程序的输出 (top 部分) 在上面 scheduler 函数其实蛮有趣的，它主要的功能就是为每个 CPU 进程调度程序。是无限循环的，为切换到所选进程，将进程 context switch 如： swtch(\u0026amp;c-\u0026gt;context, \u0026amp;p-\u0026gt;context);\n在操作系统中，当内核完成所有的初始化操作后，会进入到第一个用户进程。这个用户进程通常是由 init 进程启动的，init 进程是所有进程的祖先进程，它是系统启动时自动创建的第一个用户进程。init 进程的 PID 为 1，它负责启动和管理其他用户进程，是系统中最后一个终止的进程。\nXV6 中的 init main 函数（user/init.c : main）\n首先这个进程的main函数创建了一个代表Console的设备。这里通过mknod操作创建了console设备。因为这是第一个打开的文件，所以这里的文件描述符0。之后通过dup创建stdout和stderr。这里实际上通过复制文件描述符0，得到了另外两个文件描述符1，2。最终文件描述符0，1，2都用来代表Console。\n1 2 dup(0); // stdout fd = 1 dup(0); // stderr fd = 2 之后 fork() 子进程运行 exec(\u0026quot;sh\u0026quot;, argv) ，来到 sh.c : main 。Shell程序首先打开文件描述符0，1，2。\n1 2 3 4 5 6 7 8 main： // Ensure that three file descriptors are open. while((fd = open(\u0026#34;console\u0026#34;, O_RDWR)) \u0026gt;= 0){ if(fd \u0026gt;= 3){ close(fd); break; } } 之后Shell向文件描述符2打印提示符“$ ”。\n1 2 3 4 5 6 7 8 9 10 int getcmd(char *buf, int nbuf) { fprintf(2, \u0026#34;$ \u0026#34;); memset(buf, 0, nbuf); gets(buf, nbuf); if(buf[0] == 0) // EOF return -1; return 0; } 值得一提的是：在 Unix 系统中，设备是由文件表示。 因此，shell 只是向 fd = 2 的 文件 写了 $ ，也就是说，fprintf () 函数用到了中断，而且是 write() 系统调用。所以由 Shell 输出的每一个字符都会触发一个 write 系统调用。最终来到 filewrite 函数(file.c) 。\n在 filewrite 函数中首先会判断文件描述符的类型。mknod 函数生成的文件描述符属于设备（FD_DEVICE = 3），而对于设备类型的文件描述符，我们会为这个特定的设备执行设备相应的 write 函数。因为我们现在的设备是 Console，所以我们知道这里会调用 console.c 中的 consolewrite 函数。\n这里先通过either_copyin将字符拷入，之后调用uartputc函数。uartputc函数将字符写入给UART设备，所以你可以认为consolewrite是一个UART驱动的top部分。uart.c文件中的uartputc函数会实际的打印字符。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 void uartputc(int c) { acquire(\u0026amp;uart_tx_lock); if(panicked){ for(;;) ; } while(1){ if(uart_tx_w == uart_tx_r + UART_TX_BUF_SIZE){ // buffer is full. // wait for uartstart() to open up space in the buffer. sleep(\u0026amp;uart_tx_r, \u0026amp;uart_tx_lock); } else { uart_tx_buf[uart_tx_w % UART_TX_BUF_SIZE] = c; uart_tx_w += 1; uartstart(); release(\u0026amp;uart_tx_lock); return; } } } uartputc 函数会稍微有趣一些。在 UART 的内部会有一个 buffer 用来发送数据，buffer 的大小是32个字符。同时还有一个为 consumer 提供的读指针和为 producer 提供的写指针，来构建一个环形的 buffer（注，或者可以认为是环形队列）。\n在函数中第一件事情是判断环形 buffer 是否已经满了。如果读写指针相同，那么 buffer 是空的，如果写指针加1等于读指针，那么 buffer 满了。当 buffer 是满的时候，向其写入数据是没有意义的，所以这里会 sleep 一段时间，将 CPU 让出给其他进程。当然，对于我们来说，buffer 必然不是满的，因为提示符“$”是我们送出的第一个字符。所以代码会走到 else，字符会被送到 buffer 中，更新写指针，之后再调用 uartstart 函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 void uartstart() { while(1){ if(uart_tx_w == uart_tx_r){ // transmit buffer is empty. return; } if((ReadReg(LSR) \u0026amp; LSR_TX_IDLE) == 0){ // the UART transmit holding register is full, // so we cannot give it another byte. // it will interrupt when it\u0026#39;s ready for a new byte. return; } int c = uart_tx_buf[uart_tx_r % UART_TX_BUF_SIZE]; uart_tx_r += 1; // maybe uartputc() is waiting for space in the buffer. wakeup(\u0026amp;uart_tx_r); // WriteReg(THR, c); // } } uartstart就是通知设备执行操作。首先是检查当前设备是否空闲，如果空闲的话，我们会从buffer中读出数据，然后将数据写入到THR（Transmission Holding Register）发送寄存器。这里相当于告诉设备，我这里有一个字节需要你来发送。一旦数据送到了设备，系统调用会返回，用户应用程序Shell就可以继续执行。这里从内核返回到用户空间的机制与trap机制是一样的。\nbottom 部分 在我们向 Console 输出字符时，如果发生了中断，RISC-V 会做什么操作。 我们之前已经在 SSTATUS 寄存器中打开了中断，所以处理器会被中断。假设键盘生成了一个中断并且发向了 PLIC，PLIC 会将中断路由给一个特定的 CPU 核，并且如果这个 CPU 核设置了 SIE 寄存器的 E bit（注，针对外部中断的 bit 位），那么会发生以下事情：\n会清除 SIE 寄存器相应的 bit，这样可以阻止 CPU 核被其他中断打扰，该 CPU 核可以专心处理当前中断。处理完成之后，可以再次恢复 SIE 寄存器相应的 bit。 会设置 SEPC 寄存器为当前的程序计数器。我们假设 Shell 正在用户空间运行，突然来了一个中断，那么当前 Shell 的程序计数器会被保存。 要保存当前的 mode。在我们的例子里面，因为当前运行的是 Shell 程序，所以会记录 user mode。 再将 mode 设置为 Supervisor mode。 最后将程序计数器的值设置成 STVEC 的值。 在 trap.c 中有可以判断中断的部分：\n1 2 3 4 usertrap： else if((which_dev = devintr()) != 0){ // ok } 在 trap.c 的 devintr 函数中，首先会通过 SCAUSE 寄存器判断当前中断是否是来自于外设的中断。如果是的话，再调用 plic_claim 函数来获取中断。\n1 2 3 4 5 6 7 8 // ask the PLIC what interrupt we should serve. int plic_claim(void) { int hart = cpuid(); int irq = *(uint32*)PLIC_SCLAIM(hart); return irq; } plic_claim 函数位于 plic.c 文件中。在这个函数中，当前 CPU 核会告知 PLIC，自己要处理中断，PLIC_SCLAIM 会将中断号返回，对于 UART 来说，返回的中断号是10。\n1 2 3 4 devintr: if(irq == UART0_IRQ){ uartintr(); } 当 irq 为 10 的时候，就调用 uartintr() 函数，向 UART 发送数据，但现在没有输入数据，UART 的寄存器为空。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 void uartintr(void) { // read and process incoming characters. while(1){ int c = uartgetc(); if(c == -1) break; consoleintr(c); } // send buffered characters. acquire(\u0026amp;uart_tx_lock); uartstart(); release(\u0026amp;uart_tx_lock); } 这个函数会将 Shell 存储在 buffer 中的任意字符送出。实际上在提示符 \u0026quot;$\u0026quot; 之后，Shell 还会输出一个空格字符，write 系统调用可以在 UART 发送提示符 \u0026quot;$” 的同时，并发的将空格字符写入到 buffer 中。所以 UART 的发送中断触发时，可以发现在 buffer 中还有一个空格字符，之后会将这个空格字符送出。\n中断并行 驱动的 top 和 bottom 部分是并行运行的。例如，Shell 会在传输完提示符“$”之后再调用 write 系统调用传输空格字符，代码会走到 UART 驱动的 top 部分（注，uartputc 函数），将空格写入到 buffer 中。但是同时在另一个 CPU 核，可能会收到来自于 UART 的中断，进而执行 UART 驱动的 bottom 部分，查看相同的 buffer。（buffer 是对于 top 和 bottom 的公有队列，对于 CPU 也一样）所以一个驱动的 top 和 bottom 部分可以并行的在不同的 CPU 上运行。\n我们在之前的代码中出现了许多 lock ，这是来管理并行。我们想要的是 buffer 只可以在同一时间被唯一个 CPU 使用。\n在 UART 中producer/consumser并发：\nproducer （shell）可以一直写入数据，直到写指针 + 1等于读指针，因为这时，buffer 已经满了。当 buffer 满了的时候，producer 必须停止运行。我们之前在 uartputc 函数中看过，如果 buffer 满了，代码会 sleep，暂时搁置 Shell 并运行其他的进程。\nInterrupt handler，也就是 uartintr 函数，在这个场景下是 consumer ，每当有一个中断，并且读指针落后于写指针，uartintr 函数就会从读指针中读取一个字符再通过 UART 设备发送，并且将读指针加1。当读指针追上写指针，也就是两个指针相等的时候，buffer 为空，这时就不用做任何操作。\n来自键盘的输出 Shell 会通过调用 read 函数 从键盘中读取字符，而接着调用 fileread 函数，因为是外设中断，之后调用 consoleread 函数 和写类似。 但是在这个场景下 Shell 变成了 consumser，因为 Shell 是从 buffer 中读取数据。而键盘是 producer，它将数据写入到 buffer 中。\n输入一个字符的：\n检测读指针和写指针是否一样，判断 buffer 是否为空，进程是否会 sleep。 在 Shell 在打印完 “$ ” 之后，如果键盘没有输入，Shell 进程会 sleep，直到键盘有一个字符输入。 所以在某个时间点，假设用户通过键盘输入了 “l”，这会导致“l”被发送到主板上的 UART 芯片，产生中断之后再被 PLIC 路由到某个 CPU 核，之后会触发 devintr 函数，devintr 可以发现这是一个 UART 中断，然后通过 uartgetc 函数 获取到相应的字符，之后再将字符传递给 consoleintr 函数。这里面有对 ASCII 码的应用（#define C(x) ((x)-'@') Control-x）。 默认情况下，字符会通过 consputc，输出到 console 上给用户查看。之后，字符被存放在 buffer 中。在遇到换行符的时候，唤醒之前 sleep 的进程，也就是 Shell，再从 buffer 中将数据读出。\n所以这里也是通过buffer将consumer和producer之间解耦，这样它们才能按照自己的速度，独立的并行运行。如果某一个运行的过快了，那么buffer要么是满的要么是空的，consumer和producer其中一个会sleep并等待另一个追上来。\n","date":"2024-03-10T16:36:08+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/xv6-%E7%9A%84%E4%B8%AD%E6%96%AD/","title":"XV6 的中断"},{"content":" 失败是成功之母\n陷阱指令和系统调用 CPU 在运行中强利将控制权交给特殊的系统代码叫陷阱（trap），其中有三种用到了：\n系统调用：syscall 当程序执行 ecall 时。 异常：指令做了非法。如除0。 设备中断系统进行1设备 I/O。 我们希望陷阱是透明的，在程序中中断是难以预料的 一般的顺序：\ntrap 强制控制权交予内核。 内核保护寄存器、内存等其它。 内核处理中断程序。 内核恢复之前保存的状态。 返回并重新恢复代码。 注：陷阱是由 CPU 上运行的当前进程导致的（其实不够准确），中断是由外部设备导致的。\nRISC -V trup 机利 用户态转到内核态 其中 vm.c 的工作是：\nECALL 指令 首先应该知道的是：\necall 指令并不会切换 page table。 将控制权交到内核 mode。 将 PC 走到 trampoline page 的地址（STVEC）。 将 PC 原来的值存到 SEPC 寄存器。 ecall 会跳转到 STVEC 寄存器 指向的指令。 之后待处理的事情：\n目前还在 user page table.需要到 Kernel 保（小心）保存32个用户寄存器 需要 kernel stack 跳转到内核中合理的 C 代码位置 总结 ecall 就是陷入 trap 陷阱的入口\n注意：至少在 XV6中，有以下几个寄存器需要注意：\n仅在 trap 中有用的寄存器。（待勘误）\nstvec ：保存 trap 处理程序的地址。 sepc ： 保存进入 trap 之前的 PC。 sret 在之后返还给 PC。 scause ：描述进入 trap 类型（原因）的（数字）数据。 sscratch ：保存 trapframe page 的地址值。 sstatus ： trap 的位控制信息，其中有 SIE、SPP 等信息。 USERVEC 指令 在 ecall 指令之后，代码的地址由 user process 到 trampoline pages 地址 PC \u0026lt;--- stvec。\n由于 RISC-V 硬件在 trap 中不会切换页表，所以在 User page table 中存在 trampoline page 的虚拟地址（在 page table 的后面），而 Kernal page table 也是一样的 mapping。\n为了保存 32个用户寄存器，我们必须需要足够的内存空间。\n不可以使用用户空间！ 因为我们不确定用户进程是否使用了栈，是否有足够的页表来可以用。是否有足够的空间来保存。\n不可以使用内核空间！（有使用的机器）: 因为我们在 trap 开始时不清楚 kernel page table 的地址，而且我们需要使用 SATP 寄存器 指向内核页表，这需要空闲寄存器（如： a0）。但是在此时，用户进程再用 a0 等寄存器。\n因此，我们需要一个特定的 page — trapframe page\n在之前内核就为每个用户页表 mapping 了这个 page。\n1 2 3 // 每个用户空间都有的 Ox3FFFFFE000 // TRAPFRAME 0x3FFFFFF000 // TRAPOLINE 在 trapframe page 有许多有趣的数据：\n1 2 3 4 5 0 ------ Kernel_satp // kemnel page table 8 ------ kernel_sp // top of process＇s kennel stack 16 ------ kernel_trap // usertrap（）address 24 ------ epc // saved user program counter 32 ------ kernel_hartid // saved kernel tp RISC-V 利用 csrrw（可 sawp 指令）将 sscratch（存有 trapframe page 地址）和 a0 寄存器 交换，接下来就是根据 a0+offset 来 sb rd, offset(a0) 完成用户寄存器的保存。 接下是使用 t0 来保存 a0。\n然后，uservec 做完大部分的任务了，接下来是取出前5个（不一定都要）数据调用 usertrup() 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ld sp，8(a0) ＃0x3fffffc000 # 将内核的SP出，取出，指向kernel stack最顶端 ld tp，32(a0) ＃ OxO (单核) # 将当前运行进程的CPU核编号取出 ld t0，16(ao) # usererap() # 将 usertrap() 函数的地址写入 t0 寄存器 ld t1，0(a0) # kernel page table ＃ 将 kernel page table 地址写入 t1 寄存器 csrw satp，t1 ＃ 注意是单向交换 sutp \u0026lt;- t1 # 将 SATP 和 t1 交换, 接下来的地址是为于 Kernel page table 中映射的。 sfence.vma zero，zero # 清空TLB jr t0 # 跳到usertrap（），执行usertrop（） 注：trampoline page 的地址映射在用户和内核的映射是相同\n小结： 使用汇编的 uservec 函数 可以 更细粒度的控制 和 更高的性能、寄存器是粒度的，需要精确控制；利用映射相同可以“无痕”完成转化换页表。\nUSERTRAP 函数 OK。 我们正式进入 trap，这个 C 函数的主要功能是确定进程进入 trap 的原因，并以确定相应的处理方式\n更改 stvec 寄存器。 这一做法取决于 trap 是由用户空间还是内核空间陷入的，将 stvec 指向内核页表，确保 trap 在内核中处理（如果 kernel 使用 trap，那就一直在内核页表，不必做多余操作，但有其他操作）。\n找到当前的进程。 根据此时 CPU 核（tp 寄存器）来找当前在 tp 上运行的进程。\n保存用户程序计数器（之前存在 sepc 中）。 这么做的原因是，trap 在执行中可能切换到另一个进程，然后可能再调用 ecall 导致 sepc 寄存器被覆盖。\n1 p-\u0026gt;traptrame-\u0026gt;epc = r-sepc(); 知道 trap 的原因。 根据触发 trap 的原因，scause寄存器 会有不同的数字如果值为 8，则是 “systsm call”，然后进入过系统调用的有关操作。 检查是否有其他进程 Kill 当前进程 对于保存在 epc的用户 PC+4 打开中断，为系统调用作中断 调用 syscallc () syscall 函数从表单中寻找系统调用编号，保护在 trap 里 a7中，（a0, a1, a2\u0026hellip; \u0026hellip;为参数, a0 一般是返回值）。最后返回，调用 usertrapret 。\nUSERTRAPRET 函数 在返回内用户空间之前，内核需要做的工作：此时，我们的 stvec 指向内核空间 trap 的处理代码。现在关闭中断，并更新 stvec\n1 w_stvec(TRAMPOLINE + (uservec-trampoline)); 最终执行 sret 指令在再重新打开中断。之后，填入 trapframe 内容（前4个）为之后用户下一次转到内核做准备。\n设置sstatus寄存器，控制寄存器\nbit 0 1 SPP sret 返回 user sret 返回supervisor SPIE 不打开中断 打开中断 将 epc-\u0026gt;sepc，设置成用户 PC 的值\n生成userret函数的参数和地址\nfn : trampeline 基础址 + 偏移量 a0 : trapframe 基址 a1 : user page table 基址\nUSERRET 函数 返回用户汇编代码\n切换用户 page table. 将参数 a1 传给 satp。（不出问题是因为trap映射一样）\n根据 trapframe（a0参数）恢复寄存器。将 trapframe 传给 t0 再传给 sscratch 。\n将 trapframe 中 a0（保存着系统调用的返回值）传给 a0 寄存器。\nsret 切换回 user mode，PC 拷贝 SEPC（之前 PC+4），重新打开中断。\n总结： trap 的系统调用为了保持隔离性，做得十分复杂。有些操作为了追求精细化用了汇编语言。\n","date":"2024-03-10T16:35:36+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/xv6-%E4%B8%AD%E7%9A%84-trap/","title":"XV6 中的 trap"},{"content":"(没写)\n","date":"2024-03-10T16:35:28+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/xv6%E7%9A%84%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/","title":"XV6的内存虚拟化"},{"content":"启动 xv6 当我们输入 make qeum 之后它会初始化自己并运行一个存储在只读内存中的引导加载程序（boot），CPU 从内存地址 0x80000000 （程序的起始位置）开始的:\n1 2 3 4 5 6 7 8 9 10 11 12 13 _entry: # set up a stack for C. # stack0 is declared in start.c, # with a 4096-byte stack per CPU. # sp = stack0 + (hartid * 4096) la sp, stack0 li a0, 1024*4 csrr a1, mhartid addi a1, a1, 1 mul a0, a0, a1 add sp, sp, a0 # jump to start() in start.c call start _entry 的指令设置了一个栈区 (stack 0)，这样 xv6就可以运行 C 代码。Xv6在 start. c 文件中为初始栈 stack0 声明了空间。由于 RISC-V 上的栈是向下扩展的，所以 _entry 的代码将栈顶地址 stack0+4096 加载到栈顶指针寄存器 sp 中。现在内核有了栈区，_entry 便调用 C 代码 start 。在其中 csrr a1, mhartid 在地址0x8000000a 上，读取了控制系统寄存器（Control System Register）mhartid，并将结果加载到了 a1寄存器。我认为是在确定几号 CPU 在设置 stack。\n在 entry. S 中没有内存分页，没有中断，没有隔离等等一切都是那么的 原始 ，在 start () 中其实就是在 M-mod (machine mode) 进行基础配置，它在寄存器 mstatus 中将先前的运行模式改为管理模式，并通过将 main() 函数的地址写入寄存器 mepc 将返回地址设为 main，它通过向页表寄存器 satp 写入0来在管理模式下禁用虚拟地址转换，并将所有的中断和异常委托给管理模式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void start() { // set M Previous Privilege mode to Supervisor, for mret. unsigned long x = r_mstatus(); x \u0026amp;= ~MSTATUS_MPP_MASK; x |= MSTATUS_MPP_S; w_mstatus(x); // set M Exception Program Counter to main, for mret. // requires gcc -mcmodel=medany w_mepc((uint64)main); // disable paging for now. w_satp(0); ...... } 最后，当做完这一切后，mepc 返回 main，并中断计时器，PC 改为 main 。 在 main() 中执行一系列的初始化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 void main() { if(cpuid() == 0){ consoleinit(); // 初始化控制台 printfinit(); printf(\u0026#34;\\n\u0026#34;); printf(\u0026#34;xv6 kernel is booting\\n\u0026#34;); printf(\u0026#34;\\n\u0026#34;); kinit(); // 物理页面分配器 kvminit(); // 内核页表 kvminithart(); // 开启分页机制 procinit(); // 进程表初始化 trapinit(); // trap向量表初始化 trapinithart(); // 安装内核trap向量 plicinit(); // 设置中断控制器 plicinithart(); // 向 PLIC 询问设备中断 binit(); // buffer cache iinit(); // inode table fileinit(); // file table virtio_disk_init(); // emulated hard disk userinit(); // first user process ... } ... } 初始化函数的调用顺序重要吗？ 重要，有些函数需要其他函数作为前置\n启动第一个进程 着重说明 userinit() 他是利用了 initcode. S 来通过调用 exec(init, argv) 以达到一个用户进程的实现\n1 2 3 4 5 6 7 # exec(init, argv) .globl start start: la a0, init # 第一个参数 la a1, argv # 第二个参数 li a7, SYS_exec ecall # 交给操作系统 接着进入到 syscall()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 void syscall(void) { int num; struct proc *p = myproc(); num = p-\u0026gt;trapframe-\u0026gt;a7; if(num \u0026gt; 0 \u0026amp;\u0026amp; num \u0026lt; NELEM(syscalls) \u0026amp;\u0026amp; syscalls[num]) { p-\u0026gt;trapframe-\u0026gt;a0 = syscalls[num](); if (p-\u0026gt;make \u0026amp; (1 \u0026lt;\u0026lt; (uint32)num)) { printf(\u0026#34;%d: syscall %s -\u0026gt; %d\\n\u0026#34;, p-\u0026gt;pid, sys_name[num], p-\u0026gt;trapframe-\u0026gt;a0); } } else { printf(\u0026#34;%d %s: unknown sys call %d\\n\u0026#34;, p-\u0026gt;pid, p-\u0026gt;name, num); p-\u0026gt;trapframe-\u0026gt;a0 = -1; } } syscalls[num]() 是函数指针·数组，它去找 exec 的系统函数 sys_exec 从 exec 进入 init 函数，init 为用户内存设置好一些东西，如 console、标准输入、标准输出和利用子进程打开 sh 。ok，结束了。\n","date":"2024-03-10T16:35:17+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/xv6%E7%9A%84%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","title":"XV6的源码解析"},{"content":"基础 利用 tmux 来实现两个终端的同时运行，具体的学习可以看这里 。 需要准备的工具。 1 2 sudo apt-get update \u0026amp;\u0026amp; sudo apt-get upgrade sudo apt-get install git build-essential gdb-multiarch qemu-system-misc \\ gcc-riscv64-linux-gnu binutils-riscv64-linux-gnu 在自己的 xv 6 目录下工作。 练习 GDB 的基本学习 \u0026ndash;\u0026gt; 这里 。 步骤 进入 xv6 的工作目录 (对于我的) 1 cd ~/workspace/xv6-labs-2021 如下： 用 tmux 进入环境，分两个屏 第一个输入 make qemu-gdb 第二个输入 gdb-multiarch 在第二中输入执行 set architecture riscv:rv64 以调试 RISCV 架构，然后执行 target remote localhost:26000（这里端口号要看 make qemu-gdb 的输出）\n(未做完)\n","date":"2024-03-10T16:35:00+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/xv6-%E7%9A%84-gdb%E8%B0%83%E8%AF%95/","title":"XV6 的 gdb调试"},{"content":"该笔记以OSTEP 为主体\n操作系统有以下四个主要的主题（来自 OSTEP），我将从四个主题慢慢钻研\nCPU 虚拟化 内存虚拟化 并发 持久性 CPU 虚拟化 什么是进程? 非正式（我认为）的说，Process 是指正在 CPU 中进行执行操作的程序，其中又包括着该程序需要的资源，即：内存、堆栈、读写的数据等。\n为什么需要进程？\n人们常常希望计算机可以同时运行多个程序。比如：在使用计算机或者笔记本的时候，我们会同时运行浏览器、邮件、游戏、音乐播放器等等。实际上，一个正常的系统可能会有上百个进程同时在运行。如果能实现这样的系统，人们就不需要考虑这个时候哪一个 CPU 是可用的，使用起来非常简单。因此我们需要解决的问题是：怎么实现同时运行？\n进程的一般函数 [[fork() 函数]]\n操作系统的机制 机制是指在操作系统中的一些低级方法或协议来实现所需的功能。例如：context switch （上下文切换），这是一种分时机制（time sharing）。\n还有一种是高级智能称作策略，是对操作系统内做出某种决定的算法。\n进程加载 在早期的（或简单的）操作系统中，加载过程尽早（eagerly）完成，即在运行程序之前全部完成。现代操作系统惰性（lazily）执行该过程，即仅在程序执行期间需要加载的代码或数据片段，才会加载。\n进程状态 运行（running）：在运行状态下，进程正在处理器上运行。这意味着它正在执行指令。 就绪（ready）：在就绪状态下，进程已准备好运行，但由于某种原因，操作系统选择不在此时运行。 阻塞（blocked）：在阻塞状态下，一个进程执行了某种操作，直到发生其他事件时才会准备运行。一个常见的例子是，当进程向磁盘发起 I/O 请求时，它会被阻塞，因此其他进程可以使用处理器。 进程 API 在现代的操作系统上，都为开发者或使用者提供了以下五类的 API\n创建（create）：操作系统必须包含一些创建新进程的方法。在 shell 中键入命令或双击应用程序图标时，会调用操作系统来创建新进程，运行指定的程序。 销毁（destroy）：由于存在创建进程的接口，因此系统还提供了一个强制销毁进程的接口。当然，很多进程会在运行完成后自行退出。但是，如果它们不退出，用户可能希望终止它们，因此停止失控进程的接口非常有用。 等待（wait）：有时等待进程停止运行是有用的，因此经常提供某种等待接口。 其他控制（miscellaneous control）：除了杀死或等待进程外，有时还可能有其他控制。例如，大多数操作系统提供某种方法来暂停进程（停止运行一段时间），然后恢复（继续运行）。 状态（statu）：通常也有一些接口可以获得有关进程的状态信息，例如运行了多长时间，或者处于什么状态。 操作系统隔离性（isolation） 进程本身不是 CPU，但是它们对应了 CPU，它们使得你可以在 CPU 上运行计算任务。所以你懂的，应用程序不能直接与 CPU 交互，只能与进程交互。 CPU 一个核运行一个进程并运行一段时间，后换另一个进程再运行一段时间\nexec 抽象了内存，使得应用程序可以在有限且“封闭”的空间运行。\nFiles 基本上来说抽象了磁盘，利用 File 数据结构来对 dick 中的块进行的读写操作\nQ.在权限切换的时候，如果设置那个 bit 位的指令必须是特殊权限指令，但是因为应用程序不应该能够设置那个 bit 到 kernel mode（即‘0’），应用程序不可以运行各种特殊权限指令了。所以那个 bit 是被保护的。 我的问题：那么，当应用程序正在使用 user mode 的时候这时会将控制权限从 user mode 切换到 kernel mode，是谁在将 bit 切换到 0（即 kernel mode）? A.我认为：在这个过程中，控制权从用户模式切换到内核模式，而这是由 CPU 内部的特权级 (machine mode??? BIOS??？)机制来控制的。\n举个例子，不论是 Shell 还是其他的应用程序，当它在用户空间执行 fork 时，它并不是直接调用操作系统中对应的函数，而是调用 ECALL 指令，并将 fork 对应的数字作为参数传给 ECALL。之后再通过 ECALL 跳转到内核。\n1 user.frok() ---\u0026gt;\u0026gt; ECALL syscall() ---\u0026gt;\u0026gt; kernel.frok() Q.在 Linux 中的 root 有全部的特权吗？ A.不会，只有特定的特权, 比一般的 user 多。\nUser/Kernel mode 切换 我们可以认为 user/kernel mode 是分隔用户空间和内核空间的边界，用户空间运行的程序运行在 user mode，内核空间的程序运行在 kernel mode。操作系统位于内核空间\n调度算法 鱼与熊掌不可兼得\n当我们在工作时间段的时候，我通常要进行资源和时间等的合理分配这是一个在现实生活中常见的管理模式，对于操作系统来说，如何管理 CPU 的资源分配是主要目的。\n我们了解了 context 的作用，即再：将要切换正在运行 CPU 上的进程时，必须先从寄存器存储目前进程的状态（内存、寄存器、指令、PC 等等）存出来内存中，再将欲执行的进程之状态读回 CPU，把进程的使用空间存来寄存器中。\nFIFO 先进先出的模式，对这个模式有个前提“进程进来的时间相同和运行时间相同”，\nSJF STCF 轮转 RR 多级反馈队列 MLFQ 批处理计算与流处理计算的区别是什么\n[[并发和并行]]\n内存虚拟化 它们是“隐形”的\n地址空间 内存操作 API 一些在 c 语言中常见的 API\nmalloc(size_t) free(void*) calloc() realloc() 忘记释放内存 这是一个很糟糕的情况\n使用自己的内存\n分段 怎样支持大地址空间？\n线程虚拟化 并发是指多个任务在同一时间段内交替执行，这些任务之间可能会有时间上的重叠，但并不一定是同时执行的。 在并发中，任务之间可能会通过时间片轮转或者事件驱动的方式来实现交替执行。\n并行是指多个任务在同一时刻同时执行，通常需要多个处理单元（比如多核处理器或者多个计算节点）来实现。 在并行中，多个任务可以同时进行，互相之间不会有时间上的重叠。\nThreads 一个工人做所有工作和两个（或多个）工人做所有工作的区别。安排时间表，轮班工作\nCritical section 1 2 3 11dd: 8b 05 31 2e 00 00 mov 0x2e31(%rip),%eax 11e3: 83 c0 01 add $0x1,%eax 11e6: 89 05 28 2e 00 00 mov %eax,0x2e28(%rip) 原子性 ","date":"2024-03-10T16:34:46+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/%E9%80%9A%E8%BF%87-xv6-%E6%9D%A5%E5%AD%A6%E4%B9%A0%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9Fostep/","title":"通过 XV6 来学习操作系统(OSTEP)"},{"content":"通过 XV6 了解操作系统 我希望通过 6. S081 的学习来学习操作系统的强大，以下的是我在学习中的笔记： 通过 XV6 来学习操作系统(OSTEP)\nXV6的gdb调试 XV6的源码解析 XV6中的trap XV6的中断 XV6的锁和并行 XV6的进程和线程 XV6的文件系统 个人 Linux 的学习 Linux个人学习记录 命令行的魅力\n分类 文件描述符\n进程（Process）和 线程（Thread）\n在 XV 6 中 Syscall 函数 系统调用 描述 int fork() 创建一个进程，返回子进程的PID int exit(int status) 终止当前进程，并将状态报告给wait()函数。无返回 int wait(int *status) 等待一个子进程退出; 将退出状态存入 *status; 返回子进程 PID。 int kill(int pid) 终止对应PID的进程，返回0，或返回-1表示错误 int getpid() 返回当前进程的PID int sleep(int n) 暂停n个时钟节拍 int exec(char *file, char *argv[]) 加载一个文件并使用参数执行它; 只有在出错时才返回 char *sbrk(int n) 按n 字节增长进程的内存。返回新内存的开始 int open(char *file, int flags) 打开一个文件；flags表示read/write；返回一个fd（文件描述符） int write(int fd, char *buf, int n) 从buf 写n 个字节到文件描述符fd; 返回n int read(int fd, char *buf, int n) 将n 个字节读入buf；返回读取的字节数；如果文件结束，返回0 int close(int fd) 释放打开的文件fd int dup(int fd) 返回一个新的文件描述符，指向与fd 相同的文件 int pipe(int p[]) 创建一个管道，把read/write文件描述符放在p[0]和p[1]中 int chdir(char *dir) 改变当前的工作目录 int mkdir(char *dir) 创建一个新目录 int mknod(char *file, int, int) 创建一个设备文件 int fstat(int fd, struct stat *st) 将打开文件fd的信息放入*st int stat(char *file, struct stat *st) 将指定名称的文件信息放入*st int link(char *file1, char *file2) 为文件file1创建另一个名称(file2) int unlink(char *file) 删除一个文件 ​ 来自表1.2：xv6系统调用（除非另外声明，这些系统调用返回0表示无误，返回-1表示出错）\nfork() 函数 exec() 函数 exit() 函数\n课程教材 book-riscv-rev2\n操作系统-三个简单的部分-ostep\n鸟哥的Linux私房菜 基础学习篇 第四版 (鸟哥)\nMIT6.S081 的实验记录 MIT6.S081 的实验问题\n","date":"2024-03-10T16:34:18+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%85%B7%E4%BD%93%E5%AD%A6%E4%B9%A0/","title":"操作系统的具体学习"},{"content":"链表介绍 链表是一种常见的数据结构，用于存储一系列元素。链表由一个个节点组成，每个节点包含数据和指向下一个节点的指针。链表的最后一个节点指向空值（nil），表示链表的结束。\n链表有多种类型，包括单向链表、双向链表和循环链表。其中：\n单向链表：每个节点包含指向下一个节点的指针。 双向链表：每个节点包含指向下一个节点和上一个节点的指针，因此可以双向遍历链表。 循环链表：最后一个节点指向第一个节点，形成一个循环。 链表相对于数组的优势在于插入和删除操作的效率较高，因为它们不需要移动大量元素。然而，链表的缺点是访问任意位置的元素的效率较低，因为它们需要从头开始遍历链表。\nGo 语言实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 package linkedlist import \u0026#34;fmt\u0026#34; /// Linked List in Golang // Linked List Data Structure type node struct { data interface{} next *node } func newLinkNode(data interface{}) *node{ return \u0026amp;node{ data : data, next : nil, } } type LinkedList struct { head *node size uint } // NewLinkedList create a linked list func NewLinkedList() *LinkedList { return \u0026amp;LinkedList{ head : nil, size: 0, } } /// Public function of linked list // Len get the linked list length func (list *LinkedList) Len() uint { return list.size } // Insert insert on the head of the linked list func (list *LinkedList) Insert(data int) *LinkedList { newNode := newLinkNode(data) newNode.next = list.head list.head = newNode list.size+=1 return list } // RemoveHead delete head node at the linked list func (list *LinkedList) RemoveHead(){ if list.head == nil{ return } list.head = list.head.next list.size-=1 } // RemoveItem delete the n node func (list *LinkedList) RemoveItem(n *node) { if n == nil { return } if n == list.head { list.RemoveHead() return } cur := list.head for cur.next != nil { if cur.next == n { cur.next = cur.next.next list.size-=1 return } cur = cur.next } } // Find find the node func (list *LinkedList) Find(data int) *node { if list.head == nil{ return nil } cur := list.head for cur != nil{ if cur.data == data{ return cur } cur = cur.next } return nil } // Head get the head node func (list *LinkedList) Head() *node { return list.head } // Print print the linked list func (list *LinkedList) Print() string { var format string cur := list.head for cur != nil { format += fmt.Sprintf(\u0026#34;%+v\u0026#34;, cur.data) cur = cur.next if cur != nil { format += \u0026#34;-\u0026gt;\u0026#34; } } // fmt.Println(format) return format } 相关算法 ","date":"2024-03-10T16:21:29+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/%E9%93%BE%E8%A1%A8go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0/","title":"链表(Go语言实现)"},{"content":"数组介绍 数组 array 是一种线性数据结构，其将相同类型的元素存储在连续的内存空间中。我们将元素在数组中的位置称为该元素的 索引 index 。\n数组的优点与局限性: 数组存储在连续的内存空间内，且元素类型相同。这种做法包含丰富的先验信息，系统可以利用这些信息来优化数据结构的操作效率。\n空间效率高：数组为数据分配了连续的内存块，无须额外的结构开销。 支持随机访问：数组允许在 �(1) 时间内访问任何元素。 缓存局部性：当访问数组元素时，计算机不仅会加载它，还会缓存其周围的其他数据，从而借助高速缓存来提升后续操作的执行速度。 连续空间存储是一把双刃剑，其存在以下局限性。\n插入与删除效率低：当数组中元素较多时，插入与删除操作需要移动大量的元素。 长度不可变：数组在初始化后长度就固定了，扩容数组需要将所有数据复制到新数组，开销很大。 空间浪费：如果数组分配的大小超过实际所需，那么多余的空间就被浪费了。 Go 语言实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 /// Array in Golang // Array Data Structure type array struct { data []int length uint } // NewArray create a array func NewArray(capacity uint) *array { if capacity == 0 { return nil } return \u0026amp;array{ data: make([]int, capacity), length: 0, } } /// Public function of array // Len get the array length func (arr *array) Len() uint { return arr.length } // Insert insert the value at the index func (arr *array) Insert(val int, ind uint) (*array, error) { if arr.isIndexOutOfRange(ind) { return nil, fmt.Errorf(\u0026#34;out of range\u0026#34;) } if arr.Len() == uint(cap(arr.data)) { return nil, fmt.Errorf(\u0026#34;full array\u0026#34;) } for i := arr.Len(); i \u0026gt; ind; i-- { arr.data[i] = arr.data[i-1] } arr.data[ind] = val arr.length++ return arr, nil } // Delete delete the value at the index func (arr *array) Delete(ind uint) (*array, error) { if arr.isIndexOutOfRange(ind) { return nil, fmt.Errorf(\u0026#34;out of range\u0026#34;) } for i := ind; i \u0026lt; arr.Len()-1; i++ { arr.data[i] = arr.data[i+1] } arr.length-- return arr, nil } // Find find the value at the index func (arr *array) Find(ind uint) (int, error) { if arr.isIndexOutOfRange(ind) { return 0, fmt.Errorf(\u0026#34;out of range\u0026#34;) } return arr.data[ind], nil } // Print print the array func (arr *array) Print(){ var format string for i := uint(0); i \u0026lt; arr.Len(); i++ { format += fmt.Sprintf(\u0026#34;|%+v\u0026#34;, arr.data[i]) } fmt.Println(format) } /// Private function of array // isIndexOutOfRange check if the index is out of range func (arr *array) isIndexOutOfRange(index uint) bool { return index \u0026gt;= uint(cap(arr.data)) } 相关算法 Bobble Sort 1 2 3 4 5 6 7 8 9 10 11 12 13 // BobbleSort bobble sort func (arr *array) Bobble() { if arr.Len() \u0026lt;= 1 { return } for i := uint(0); i \u0026lt; arr.Len(); i++ { for j := uint(0); j \u0026lt; arr.Len()-i-1; j++ { if arr.data[j] \u0026gt; arr.data[j+1] { arr.data[j], arr.data[j+1] = arr.data[j+1], arr.data[j] } } } } Binary Search 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // BinarySearch func (arr *array) BinarySearch(tar int) int { var ( low = 0 high = int(arr.Len()) - 1 ) for low \u0026lt;= high { mid := low + (high-low)/2 if arr.data[mid] \u0026gt; tar { high = mid - 1 }else if arr.data[mid] \u0026lt; tar { low = mid + 1 }else{ return mid } } return -1 } ","date":"2024-03-10T16:21:29+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/%E6%95%B0%E7%BB%84go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0/","title":"数组(Go语言实现)"},{"content":"","date":"2024-03-10T16:21:29+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/%E6%A0%88go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0/","title":"栈(Go语言实现)"},{"content":"gdb调试命令 gdb是一个在UNIX环境下的命令行调试工具\n进入gdb 1 2 3 4 # 先进入编译 gcc \u0026lt;program\u0026gt;.c -g -o \u0026lt;program\u0026gt; # 编译后在 gdb \u0026lt;program\u0026gt; 基本命令 1）查看源码　1 (gdb) l 源码会进行行号提示。\n如果需要查看在其他文件中定义的函数，在l后加上函数名即可定位到这个函数的定义及查看附近的其他源码。或者：使用断点或单步运行，到某个函数处使用s进入这个函数。\n2）设置断点　1 2 3 (gdb) b（reak） fun or (gdb) b row 这样会在运行到源码第6行时停止，可以查看变量的值、堆栈情况等；这个行号是gdb的行号。\n3）查看断点处情况 1 (gdb) info b 可以键入\u0026quot;info b\u0026quot;来查看断点处情况，可以设置多个断点；\n4）运行代码 1 (gdb) r 5）显示变量值 1 (gdb) p n 在程序暂停时，键入\u0026quot;p 变量名\u0026quot;(print)即可；\nGDB在显示变量值时都会在对应值之前加上 $N 标记，它是当前变量值的引用标记，以后若想再次引用此变量，就可以直接写$N，而无需写冗长的变量名；\n6）观察变量 1 (gdb) watch n 在某一循环处，往往希望能够观察一个变量的变化情况，这时就可以键入命令\u0026quot;watch\u0026quot;来观察变量的变化情况，GDB在\u0026quot;n\u0026quot;设置了观察点；\n7）单步运行 1 (gdb) n 8）程序继续运行 1 (gdb) c 使程序继续往下运行，直到再次遇到断点或程序结束；\n完整的gdb调试 退出gdb 1 2 # 输入\u0026#39;q\u0026#39; (gdb) q （施工中🚧）\n","date":"2023-04-24T19:10:36+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/gdb%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/","title":"GDB基本使用"},{"content":"MakeFile的编译和连接 对于大量的c语言文件一个很好的自动化工具,其实可以用到任何语言\nMakeFile的一般使用 使用规则 既然要用MakeFile，那就要知道它是怎么使用的；主要还是编译\u0026amp;链接，将大量的文件，通过直接或间接的方式来一键编译，就不必像gcc -g -o pro1.c pro2.c pro3.c... filename如此这般麻烦的编译了。\n写入Make的文件的规则:\n如果这个工程没有编译过，那么我们的所有c文件都要编译并被链接。 如果这个工程之中的某几个c文件被修改，那么我们只编译被修改的c文件，并链接目标程序。 如果这个工程的头文件被改变了，那么我们需要编译引用了这几个头文件的c文件，并链接目标程序。 对makefile的书写规则：\n1 2 3 4 target ... : prerequisites ... command ... ... target: 这个是的目标文件，也可以是一个执行文件，还可以是一个标签（label）。 prerequisites: 这个是一个依赖文件，是对target文件的输入。 command: 这个是对文件的命令具体操作。eg：cc -o file.h 简而言之，target这一个或多个的目标文件依赖于prerequisites中的文件，其生成规则定义在command中。\nmake的使用技巧 变量的使用 在makefile里面也是可以使用变量的，但是这是不可变的(是不是有点矛盾),它更像是c语言里面的宏(#define)。\n1 object = $(boo) 这样的好处是我们可以简化我们的make文件，是它不是这么的杂乱无章。\n书写规则 ","date":"2023-04-24T19:08:45+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/makefile%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","title":"MakeFile使用笔记"},{"content":"入门 微处理器历史 Intel的x86 在这里我想来简单的说道说道微处理器的历史发展，特此说明一下我不是专业的🙄，因此我没有详细的深入研究，如果有任何的错误请告诉我，谢谢。\n自从1971年的Intel4004既第一款微处理器，也是全球第一款微处理器开始，我们人类社会标志着进入微芯片时代，在这个时代有三个主要的趋势：\n处理器的位长的倍增 指令集的快速发展 时钟频率的快速增加 Intel也逐步发布了Intel 8008一个8位的，Intel 8086 一个16位的，至此，Intel的x86帝国开始了。在1985年，Intel的32位处理器IA32问世，而随着摩尔定律等的种种限制，单核的处理器已经遇到瓶颈了，各大公司继而转向了高频率、低功耗的多核处理器，处理器进入多核/多线程时代（2005）。\n在一些无论是竞争关系，还是研究关系，导致目前的市场上出现了两种指令集计算机\nCISC(Complex instruction set computer) RISC(Reduced instruction set computer) 在后面我会再提到的。\n我不知道未来的处理器向哪个方向发展，也不知道Intel是否一直在前沿（AMD：呵呵），但我相信，人类的智慧使得世界自第二次工业革命以来史无前例的大发展，在未来一定有着不一样的发展。\n基本概念 嗯嗯，回来回来，不去想未来，做好当下。\n在了解具体的体系系统前，我们来了解基本的一些东西：\n上面是来自CS61c的图片，我们现在要了解就是整个软件到硬件的过程，也可以说是抽象到具体的过程。\nInstructure Set Architecture：指令集架构 (包括指令规格，不同规则寄存器等)，简称ISA，它是软硬件之间的桥梁。\nProcessor、Memory、I/O system：这是由OS进行控制的。\n我们这章主要的是学习ISA，CSAPP主要是x86-64的CISC指令集，CS61c主要是RISC-V的RISC指令集，没错，它们是不同的指令集，在我的笔记里面我也会不时的写上RISC-V的一些表示来证明我学习过了（笑）。\n什么是编译 1 2 高级语言 --\u0026gt; 汇编语言 --\u0026gt; 机器语言 在我们的零章的时候我说过一个*.c文件如何变成的一个可执行的程序的一个主要过程，它有一个步骤是编译，这是一个我们需要细细品味的步骤。\n编译过程是一个由某个高级语言（比如c文件）经过编译器的一系列的处理成为可读性低的汇编语言。换而言之，就是把我们十分清楚明白的抽象语言转换成机器语言（值得注意的是，此时机器也不知道汇编语言），在经历汇编译器翻译成二进制代码，真正的机器语言，机器可以读懂了，但我们看不懂（除了某些黑客）。\n上面是cs61c中的从C到机器语言的完整过程，十分的详细了。程序的运行就是想像是一个翻译过程，用上一些我们明文规定的语法规则，使用编译器（GCC等）来当我们程序员和机器之间的翻译官。\n现在来看一看从 C语言 到机器代码(一个整型加法计算的汇编代码)\n1 2 3 4 5 6 7 8 9 10 11 12 // filename: clcyle_one #include \u0026lt;stdio.h\u0026gt; int main(int argc, char const *argv[]) { int sum = 0; for (int i = 0; i \u0026lt; 10; ++i) { sum += i; } return 0; } 经过gcc的编译，在自己的Linux机器上使用以下的代码\n1 $ gcc -Og -S clcyle_one.c 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 .file \u0026#34;clcyle_one.c\u0026#34; .text .globl main .type main, @function main: .LFB7: .cfi_startproc movl $0, %eax jmp .L2 .L3: addl $1, %eax .L2: cmpl $9, %eax jle .L3 movl $0, %eax ret #（不用在意类似 .file 的指令，它们是伪指令， 要从main看起） 两者相互比较一下我们可以发现，C 语言代码被处理成统一格式的汇编代码，在汇编代码中，第一个字符串叫做操作符，后面的是源和目的寄存器（这是一个大玩意😣）。操作和操作数明确，在下面我们会到不同的操作符分类分析（我想把RISC-V的加入作比较），记住一个条件，读取/运算操作是一个线性逐句逐次的操作，PC指令是有现态和次态之分。\n处理器的工作 在我们对操作指令分类讨论之前我们来认识处理器是怎么工作的，\n上面的图片(分别来自CSapp和CS61c)十分清楚的展示了处理器对于存放在主存里面的指令有着什么样的操作，主要的就两点存、读取值和计算。在x86-64里面还有一个叫作条件码的东东，我会在下面说到因为我也第一次看见这个。\n这是一个CPU到Memory的一个过程，具体的是一个处理器从内存某个地址取值（有数据和指令）拿到CPU里的寄存器通过ALU计算，再根据PC选择下一步。\n程序计数器(PC, Program counter) - 存着下一条指令的地址，在 x86-64 中称为 RIP。\n寄存器(Register) - 用来存储数据以便操作。\n条件代码(Codition codes) - 通常保存最近的算术或逻辑操作后的信息，用来做条件跳转的条件。\n什么是ISA Instruction Set Architecture (指令集框架) 是包含了针对某个特定处理器执行的基本操作码（opcode），里面是基本命令，在我们学习的x86-64、RISC-V都有不同的ISA。\n为了学习方便，我们一般要把ISA根据使用的方法不同进行不同的分类。\n资料处理与访问操作 算术逻辑操作 控制过程操作 在下面我会一一分析。\nCISC\u0026amp;RISC区别 CISC(Complex instruction set computer)\n兼容性性强，指令繁多，长度可变，由微程序实现。 代表：x86-64\nRISC(Reduced instruction set computer)\n指令少，使用频率接近，主要是依靠硬件实现（通用寄存器、硬布线逻辑控制）。 代表：RISC-V\n开始快乐的汇编 整型寄存器 在x86-64上有16个64位的通用寄存器；对于每个寄存器的低32、16和8位可以独立地通过其他不同指令名称访问，原则上，几乎任何寄存器都可以用于保存几乎任何逻辑和算术操作的操作数，但有些具有特殊或受限制的用途。\n一个寄存器有着64位、32位、16位、8位这可以对以前的低位程序向下兼容。\n按照惯例，%rsp被保留作为堆栈指针，并且因为一些指令（例如push、pop、call）隐含使用它。%rsp指向最低占用的堆栈位置（而不是下一个要使用的位置）。\n寄存器%rbp有时被用作帧指针，即当前堆栈帧的基址。指令计数器寄存器（％rip） 指向要执行的下一条命令; 程序员无法直接访问它, 但是大量地被用作基于位置无关代码寻址的基础。还有一些其他指令隐含地使用某些寄存器；例如，整数乘法和除法指令需要%rax和%rdx。\n数据类型 既然我们的寄存器有着不同位的表示，那就是说处理器在操作不同的数据时使用着不同位数的寄存器来提高速率。\n我们针对不同的数据类型使用不同的suffix和size：\nData type suffix size word char b 1B Byet short w 2B 1word int l 4B 2word long q 8B 4word char* q 8B 4word float s 4B 2word double l 8B 4word 上面的suffix列显示了在 GNU 汇编程序用来指定适当大小的变体的字母指示。\n而一个新单位word是相等于2个字节的大小。\n操作数指示符 操作数基本 以下的都是在操作数里面主要数值表达的意思：\nImm refers to a constant value, e.g. 0x8048d8e or 48 r refers to a register. e.g. %rax or %edi R[r] refers to the value stored in register address r. M[i] refers to the value stored at memory address i . 不同的格式表示不同的类型。\n寻址 很重要！！！\n对于寻址来说，比较通用的格式是：Imm(Rb, Ri, S) -\u0026gt; M[R[Rb] + S*R[Ri]+ Imm]，其中：\nImm - 常数偏移量 Rb - 基寄存器 Ri - 索引寄存器，不能是 %rsp S - 系数 指令 接下来我们就来看看不同分类的指令格式，我按书上的顺序来说的，它也是按我们在平时使用的频率顺序来教的。\n大多数的指令都是使用上文提过的 suffix 来显示操作数的大小的。\n数据移动指令 对于 mov 指令来说，需要源操作数和目标操作数。指令的具体格式可以这样写 mov? Src, Dest，第一个是源操作数，第二个是目标操作数\n1 2 3 4 5 6 mov[b|w|l|q] Src, Dest # 将src移动到dest movs[bw|bl|bq|wl|wq|lq] Src, Dest # 带符号扩展的移动 movz[bw|bl|bq|wl|wq] Src, Dest # 带零扩展的移动 movabsq imm, r # 移动绝对四字（imm为64位） cltq Src, Dest # 把%eax 符号扩展到%rax 在使用 mov 指令的时候需要值得注意的是我们的源值和目的值的选址是有标准的, 源操作数可以是立即数、寄存器值或内存值的任意一种，但目标操作数只能是寄存器值或内存值\nSrc Dest imm Rag imm Mem Reg Reg Reg Mem Mem Reg 只有这五种的选择 ， 如果要把Mem -\u0026gt; Mem 的值移动，需要两步 Mem -\u0026gt; Reg -\u0026gt; Mem\n程序栈指令 这一部分就只有两个主要的指令，但是无比的重要。可以把数据压入程序栈中，以及在栈中弹出，程序栈在过程调用中起至关重要的作用。\n1 2 pushq Src # 将4word的数据压入栈，并把%rsp - 8 -\u0026gt; %rsp popq Dest # 将4word的数据弹入栈，并把%rsp + 8 -\u0026gt; %rsp 对于程序栈指令十分重要的一点是我们对内存的变化要注意。在程序员的眼里内存是一个有限的数组，我们在把寄存器里面的数据 push 进内存的时候栈指针（%rsp）要向着地址减小的方向移动，这就是 %rsp - 8 的原因。\n图片\n算术与逻辑指令 对于算术指令我们想起CPU中最重要的部件 ALU 算术逻辑单元，基本上所有的这些指令通过 opcode 来在多路选择上 指挥 ALU正确的使用算术。\n\u0026gt; 注：下面的所有指令都可以根据数据类型加 suffix (b/w/l/q)\nUnary Operation(一元操作) 1 2 3 4 inc Deat Deat+1-\u0026gt;Deat # 按1递增 dec Deat Deat-1-\u0026gt;Deat # 按1递减 neg Deat -Deat-\u0026gt;Deat (取反) # 算术取反 not Deat ~Deat-1-\u0026gt;Deat （取补） # 按位取反 一元操作只有一个操作数，即做源也是目的。可以是Reg or Mem 。\nBinary Operation(二元操作) 1 2 3 4 5 6 7 leaq S，D \u0026amp;S -\u0026gt; D # 将源地址的有效地址加载到目标中 add S，D D + S -\u0026gt; D # 将源加到目标中 sub S，D D - S -\u0026gt; D # 将源从目标中减去 imul S，D D * S -\u0026gt; D # 目标乘以源 xor S，D D ^ S -\u0026gt; D # 按位异或目标和来源 or S，D D | S -\u0026gt; D # 按位或目标和来源 and S, D D \u0026amp; S -\u0026gt; D # 按位与目标和来源 对于第二个到最后一个不需要再说了，都是字面意思。主要来说一说 leaq 这个指令。\nLoad effective address(加载有效地址) , leaq 有两个作用：\n将其源操作数的有效地址（而不是该地址处的数据）加载到其目标寄存器中 在 C语言里面就是 \u0026amp;S , 这样的好处是可以给下面的内存产生指针。 也可用于执行与寻址无关的算术运算。（eg： leaq (%rdi, %rsi, 4), %rax 相同与 x + 4*y ) Shift Operations(移位操作) 1 2 3 sal[b|w|l|q] imm,d d = d \u0026lt;\u0026lt; imm # 左移imm位 sar[b|w|l|q] imm,d d = d \u0026gt;\u0026gt; imm # 算术右移imm位 shr[b|w|l|q] imm,d d = d \u0026gt;\u0026gt; imm # 逻辑右移imm位 Special Arithmetic Operations(特殊算术操作) 1 2 3 4 5 6 imulq S # 有符号全乘法 四字到八字 mulq S # 无符号全乘法 四字到八字 idivq S # 有符号全除法 八字到四字 divq S # 无符号全除法 八字到四字 cltd # sign extend %eax into %edx::%eax cqto # sign extend %rax into %rdx::%rax 在特殊算术里面，这样的设计是为了补码的乘除有扩展。由两个64位的到全128位的乘积和整数除法的截断。\n除法需要特殊的安排：idiv（有符号） 和 div（无符号） 操作在2n字节被除数和n字节除数上，产生一个n字节商和n字节余数。被除数总是存在于一对固定寄存器中（32位情况下为%edx和%eax；64位情况下为%rdx和%rax）；除数作为指令中的源操作数来指定。商放在％eax（resp. ％rax）中; 余数放在％edx（resp. ％rdx）中。对于有符号的除法，使用cltd（resp.ctqo）指令来准备％edx(resp.%rdx)，并将其与％eax(resp.%rax)的符号扩展配合使用。例如，如果a、b、c是保存四个字长的内存位置，则可以使用以下序列设置c = a / b：\n1 2 3 4 movq a(%rip), %rax ctqo idivq b(%rip) movq %rax, c(%rip) 上文来自文档）\n控制指令 到目前为止，我们看到的都是顺序一条接着一条的操作的，但是在我们的c语言里面还有条件语句（if）、循环语句（while）、分支语句（switch）等，很明显都不是顺序的，要进行某种跳转，而这种跳转是由机器代码来实现的，根据测试数据值来判断机器此时是否改变控制流。\n条件码 好了，到我们心心念的条件码了，条件码在CPU中是有单独的条件码寄存器，但是它只有单个位，它们描述的是距离最近的算术和逻辑操作的某些属性，CPU根据条件码寄存器来断定是否执行分支跳转。以下是四种条件码：\nZF result was Zero CF result caused Carry out of most significant bit (unsigned) SF result was negative (Sign bit was set) OF result caused (signed) Overflow （negative overflow, positive overflow） leaq 指令不改变任何的条件码。而不是所有的指令都要改变，如xor对于CF、OF会设置为0。\n指令集中也有专门来设置条件码的指令，它们不会改变任何的其他寄存器，只会改变条件码：\n1 2 3 4 cmp[b|w|l|q] s2,s1 # 比较两个值，S1 - S2 用减法的方法来比较 test[b|w|l|q] s2,s1 # 测试两个值，S1 \u0026amp; S2 可以来检查是负or正，也可以比较具体位的值 其实cmp和test有时是十分好用的测试指令，比如在对（x == 0）的时候，可以用 cmpl %eax, %eax 或者 testl %eax, %eax 来与自己比较来设置ZF条件码，也用来判断 %eax 是正数或负数。\n访问条件码 条件码通常是不会直接读取的，在x86中采用三种使用方式：\n可以根据条件码的某种位逻辑组合，将一个字节设置为0 或1。 可以条件跳转到程序的某个其他的部分。 可以有条件地传送数据。 这里会发现用了位的逻辑计算来确认大于或小于等情况。（需要好好看看第二章）\n第一点的实现 SET指令 1 2 3 4 5 6 7 8 9 10 11 12 sete / setz D Set if equal/zero ZF setne / setnz D Set if not equal/nonzero ~ ZF sets D Set if negative SF setns D Set if nonnegative ~ SF setg / setnle D Set if greater (signed) ~ (SF ^ 0F)\u0026amp; ~ ZF setge / setnl D Set if greater or equal (signed) ~ (SF ^ 0F) setl / setnge D Set if less (signed) SF^0F setle / setng D Set if less or equal (SF ^ OF)|ZF seta / setnbe D Set if above (unsigned) ~ CF\u0026amp; ~ ZF setae / setnb D Set if above or equal (unsigned) ~ CF setb / setnae D Set if below (unsigned) CF setbe / setna D Set if below or equal (unsigned) CF|ZF SET指令，每条指令根据条件码的各种组合将一个字节设置为 0或1。\n第二点的实现 Jump指令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 jmp Label Jump to label true jmp *Operand Jump to specified location true je / jz Label Jump if equal/zero ZF jne / jnz Label Jump if not equal/nonzero ~ ZF js Label Jump if negative SF jns Label Jump if nonnegative ~ SF jg / jnle Label Jump if greater (signed) ~ (SF ^ 0F)\u0026amp; ~ ZF jge / jnl Label Jump if greater or equal (signed) ~ (SF ^ 0F) jl / jnge Label Jump if less (signed) SF^0F jle / jng Label Jump if less or equal (SF ^ OF)|ZF ja / jnbe Label Jump if above (unsigned) ~ CF\u0026amp; ~ ZF jae / jnb Label Jump if above or equal (unsigned) ~ CF jb / jnae Label Jump if below (unsigned) CF jbe / jna Label Jump if below or equal (unsigned) CF|ZF 跳转(jump) 指令会导致执行切换到程序中一个全新的位置。在汇编代码中，这些跳转的目的地通常用一个标号(Label) 指明。在下一个标题再继续深入jump指令。\n第三点的实现 cmove指令 1 2 3 4 5 6 7 8 9 10 11 12 cmove / cmovz S, D Move if equal/zero ZF cmovne / cmovnz S, D Move if not equal/nonzero ~ ZF cmovs S, D Move if negative SF cmovns S, D Move if nonnegative ~ SF cmovg / cmovnle S, D Move if greater (signed) ~ (SF ^ 0F)\u0026amp; ~ ZF cmovge / cmovnl S, D Move if greater or equal (signed) ~ (SF ^ 0F) cmovl / cmovnge S, D Move if less (signed) SF^0F cmovle / cmovng S, D Move if less or equal (SF ^ OF)|ZF cmova / cmovnbe S, D Move if above (unsigned) ~ CF\u0026amp; ~ ZF cmovae / cmovnb S, D Move if above or equal (unsigned) ~ CF cmovb / cmovnae S, D Move if below (unsigned) CF cmovbe / cmovna S, D Move if below or equal (unsigned) CF|ZF 条件传送指令, 但传送条件满足的时候,指令把S复制到D中。\nC语言中的条件分支 现在来进行对C语言中一些常见的分支跳转操作来看看翻译后的机器代码。\nif-else C 语言中的江-else 语旬的通用形式模板如下：\n1 2 3 4 if (test-expr) then-statement else els-statement 汇编器工作是为 then-statement 和 else-statement 产生各自的代码块。它会插入条件和无条件分支，以保证能执行正确的代码块。\n看一个例子\n1 2 3 4 5 6 7 8 9 10 long absdiff(long x, long y) { long result; if (x \u0026lt; y) result = y-x; else result = x-y; return result; } 1 2 3 4 5 6 7 8 9 10 long absdiff_es(long x, long y) { long result; if (x \u0026gt; y) result = x-y; else result = y-x; return result; } 分别产生的汇编代码\n1 2 3 4 5 6 7 8 9 # x in %rdi, y in %rai absdiff : movq %rsi, %rax subq %rdi, %rax rval = y-x movq %rdi, %rdx subq %rsi, %rdx eval = x-y cmpq %rsi, %rdi 比较 x:y cmovge %rdx, %rax If \u0026gt;=, rval = eval ret Return tval 1 2 3 4 5 6 7 8 9 10 11 absdiff_es: cmpq %rsi, %rdi jle .L4 movq %rdi, %rax subq %rsi, %rax ret .L4: # x \u0026lt;= y movq %rsi, %rax subq %rdi, %rax ret [为什么基于条件数据传送(1)的代码会比基于条件控制转移(2)的代码性能要好？]\nwhile while 语句的通用形式如下：\n1 2 while (test-expr) body-statement 例子\n1 2 3 4 5 6 7 8 9 long fact_while(long n) { long result = 1; while (n \u0026gt; 1) { result *= n; n = n-1; } return result; } do-while do-while 语句的通用形式如下：\n1 2 3 do body-statement while (test-expr); 例子\n1 2 3 4 5 6 7 8 9 10 11 12 // Do While 的 C 语言代码 long pcount_do(unsigned long x) { long result = 0; do { result += x \u0026amp; 0x1; x \u0026gt;\u0026gt;= 1; } while (x); return result; } 产生的汇编代码\n1 2 3 4 5 6 7 8 9 movl $0, %eax # result = 0 .L2: # loop: movq %rdi, %rdx andl $1, %edx # t = x \u0026amp; 0x1 addq %rdx, %rax # result += t shrq %rdi # x \u0026gt;\u0026gt;= 1 jne .L2 # if (x) goto loop rep # ret for for 循环的通用形式如下：\n1 2 for (init-expr; test-expr; update-expr) body-statement switch switch 循环的通用形式如下：\n1 2 3 4 5 6 7 8 switch(n){ case test-expr: body-statement break; case test-expr: body-statement break; } 对于C语言的这些语法我只是在这里举出例子来，最好看看书上的讲解。\n分支跳转(RISC-V) 对于这个分类其实我分给了RISC-V， 主要是在x86-64中的控制指令和RISC-V的分支跳转其实是一回事，主要区别是否使用的条件码（其实在我看来RISC-V也用了条件码，但是是隐式的使用）。\nRISC-V的 Branch Instruction\n1 2 （施工中🚧） 过程调用 过程是软件中一种很重要的抽象。它提供了一种封装代码的方式，用一组指定的参数和一个可选的返回值实现了某种功能。然后，可以在程序中不同的地方调用这个函数。设计良好的软件用过程作为抽象机制，隐藏某个行为的具体实现，同时又提供清晰简洁的接口定义，说明要计算的是哪些值，过程会对程序状态产生什么样的影响。不同编程语言中，过程的形式多样：函数(function) 、方法(method) 、子例(subroutine) 、处理函数(handler) 等等，但是它们有一些共有的特性。\n过程调用主要有三个机制：\n控制传递。包括如何开始执行过程代码，以及如何返回到开始的地方。本质上是代码执行地址的改变和切换。\n数据传递。调用函数时要传给函数一些参数，在返回函数时也可能会将一些函数计算结果以返回值形式返回给原函数。本质上是数据传入新过程，又传回原过程。\n内存管理。在过程进行时，如何分配内存空间；在过程返回后，如何销毁内存中存储的局部变量。\n数据存储分配 外部链接 摩尔定律\u0026mdash;Wiki\n微处理器\u0026mdash;Wiki\nThe 50 Year History of the Microprocessor\n芯片相关\u0026ndash; Cpu历史\u0026ndash;AMD系列\n芯片相关\u0026ndash; Cpu历史\u0026ndash;intel系列\n【读薄 CSAPP】贰 机器指令与程序优化\nRISC-V手册\nRISC-V基本指令集概述\n过程调用\n","date":"2023-04-09T20:13:06+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/%E4%BA%8C.%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9C%BA%E5%99%A8%E7%BA%A7%E8%A1%A8%E7%A4%BAcsapp/","title":"二.程序的机器级表示(CSAPP)"},{"content":"二进制系统的核心\u0026mdash;bit 众所周知，在计算机里面的所以数据都是由bit表示的，可能这与我们日常使用的十进制来说是十分不方便的，而要想从现实世界的十进制到二进制的过程需要一点点的改变。\n正如我们所想的一样，bit的表示符合物理的形式，更加的底层，也与数学上的息息相关。当我们终究是要从程序员的看发来看bit的，对我们来说，计算机就是通过对bit进行不同方式的编码和描述，来完成和执行不同的任务。\n信息存储 二进制和十六进制 下面是各个进制的转换:\n二进制 十进制 十六进制 二进制 十进制 十六进制 0000 0 0 1000 8 8 0001 1 1 1001 9 9 0010 2 2 1010 10 A 0011 3 3 1011 11 B 0100 4 4 1100 12 C 0101 5 5 1101 13 D 0110 6 6 1110 14 E 0111 7 7 1111 15 F 这是一个十分重要的表格，我们要记得它。\n位， 字节， 字（bit, Byte, word） 我们的一个位就是一bit， 一个字节就是8个bit， 一般32位字长机器一个字就是4个bit。\n如果你问我为什么要这么规定的话，我可以告诉你我也不知道，笑，可以去看看历史，我猜是这样的设计符合机器的一些特性。\n在C语言里面，所有的数据类型都有分配好的字节数，char：1字节、short：2字节、int：4字节、long： 4字节、float：4字节、double：8字节（均在32位机器上）等等。\n分配成这样：\n有规范，可以在不同的机器程序可以运行。 机器没有无限大的内存。 寻址和字节顺序 在内存里，我们把它们抽象成一个一定大的数组块，为每一均匀分布的地址块编上编号(图片)，因此我们要知道多字节的存储顺序，这对于我们在进行网络数据的发送/接收格式，阅读反汇编的时候等等有关系。\n大小端的判定：\n以下是我使用书中的代码看我的电脑是大端还是小端：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 typedef unsigned char *byte_pointer; void show_bytes(byte_pointer start, size_t len) { size_t i; for (size_t i = 0; i \u0026lt; len; i++) { printf(\u0026#34;%.2x \u0026#34;, start[i]); } printf(\u0026#34;\\n\u0026#34;); } void show_int(int x) { show_bytes((byte_pointer)\u0026amp;x, sizeof(int)); } int main(int argc, char const *argv[]) { short a = -12345; unsigned short ua = a; printf(\u0026#34;number = %d\\n\u0026#34;, a); show_int(a); printf(\u0026#34;number = %d\\n\u0026#34;, ua); show_int(ua); return 0; } ==========================\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; $ ./byte number = -12345 c7 cf ff ff number = 53191 c7 cf 00 00 // 我的电脑是小端的 // 系统Linux: Alpine apk-tools 2.12.9, compiled for x86_64. 位的Boolean Algebras 位的布尔运算可以看我的这一篇\n左移和右移的计算 这里我想着重的记下来： 对于左移\u0026lt;\u0026lt;\u0026amp; 右移\u0026gt;\u0026gt; 是对于位的计算，相比于右移来说左移比较简单，在移动的同时往最低位右边补 0 即可。右移的话有两种类型，一种是逻辑右移（左边补 0），另一种是算术右移（左边补符号位）。为什么会有这两种，因为对应无符号数和有符号数的运算是不同的计算方法。\nC语言上的logic计算 不必多言，做题：\n1 2 3 4 5 6 7 8 9 10 11 12 // P76 练习题2.44 int x = foo(); int y = bar(); unsigned ux = x; unsigned uy = y; x \u0026lt; 0 =\u0026gt; ((x * 2) \u0026lt; 0) ux \u0026gt;= 0 x \u0026amp; 7 == 7 =\u0026gt; (x\u0026lt;\u0026lt;30) \u0026lt; 0 ux \u0026gt; -1 x \u0026gt; y =\u0026gt; -x \u0026lt; -y 整数表示 无符号表示 无符号数（unsigned），就是在0~2[^w] - 1范围的数，w是表示字长。有一个重要的特性，就是每个介于0~2[^w]-1 之间的数都有唯一的一个w位的值编码。\nUMin = 0; UMax = 2[^w]−1; 补码表示 补码（Two\u0026rsquo; s Complement）， 就是在-2[^w-1] ~ 2[^w-1] - 1范围的数，补码的出现使得数据的表示得到最好的利用，在运算上和我们的计算自觉一样了，只有一个0没正负之分。\nTMin = -2[^w-1] TMax = 2[^w-1] - 1 我们可以从上面得到一些特性：\n|TMin| = |TMax| + 1 UMax = 2 |TMax| + 1 = 2 |TMin| - 1 整数运算 加法 考虑两个非负整数x 和y, 满足0 \u0026lt; x, y \u0026lt; 2[^w] 。每个数都能表示为w位无符号数字。然而， 如果计算它们的和，我们就有一个可能的范围0 \u0026lt; x+y \u0026lt; 2[^w+1]-2 。我们需要w+1位\n8 11 3（19） 1000 + 1011 = 10011 我们来想想补码的形式，两个数x，y满足-2[^w-1] \u0026lt; x, y \u0026lt; 2[^w-1]-1, 计算它们的和，我们就有一个可能的范围-2[^w] \u0026lt; x + y \u0026lt; 2[^w-1]-2。\n8 11 3（19） 1000 + 1011 = 10011 乘法 无符号数的乘法就是UMul(x,y) = x * y mod 2[^w]\n补码的乘法TMul(x,y) = U2T(x * y mod 2[^w])\n溢出 在我们的运算中（特别是很大的数）不仅仅只考虑算不算的对，还要考虑有没有溢出，一旦我需要的位变成w+1的十分你要十分注意了。\n[\n此时我们要用上扩展与截取：\n扩展：\n对于无符号数，用x位向量表示[xn-1,\u0026hellip;,x0] -\u0026gt;[0,0,0,0,xn-1,\u0026hellip;,x0],用0把剩下的位补齐 对于补码， 用x位向量表示[xn-1,\u0026hellip;,x0] -\u0026gt;[ xn-1,xn-1,xn-1,xn-1,\u0026hellip;,x0],用最高位xn-1把剩下的位补齐 截取： 对于无符号数，UAdd(u,v) = u+v mod 2[^w], UMult(u,v) = u * v mod 2[^w] 对于补码，先把数转换成无符号数再模运算最后再转换补码， TAdd(u,v) = U2T(u+v mod 2[^w]), TMult(u,v) = U2T(u * v mod 2[^w]) 类型转换 无符号数和补码的转换是对位的表示不同来达到转换的过程。\n浮点数（floating point） 关于浮点数，本质上就是我们如何使用二进制来表达一个很大或者很小的数 (类似科学计数法，但是编码上有显著的区别)。\n由于二进制的数值系统在表达能力上存在一定的限制 (位数的限制)，我们实际上没有办法表示所有的数，因此浮点数的设计需要认真的权衡和折中，既要考虑能够表达的范围，也要考虑表达的精度。\n浮点数是一种近似的数，和我们十进制中的小数（或分数）一样，比如：3/10 = 0.333！。所以浮点数在不论大小项目里面都是要十分小心的地方。\nIEEE 浮点表示 IEEE 浮点标准用V=(-1)[^s] M 2[^E]的形式来表示一个数：\n符号(sign) s 决定这数是负数(s=1) 还是正数(s=0), 而对于数值0的符号位解释 作为特殊情况处理(-0.0 = +0.0)。 尾数(significand) M 是一个二进制小数，它的范围是1~2-£, 或者是0~1 - £。 阶码(exponent) E 的作用是对浮点数加权，这个权重是2 的E 次幕（可能是负数） 。 将浮点数的位表示划分为三个字段，分别对这些值进行编码： 一个单独的符号位s 直接编码符号s 。 k 位的阶码字段exp=ek - 1 … e1,e0 编码阶码E 。 n 位小数字段frac= fn-1 \u0026hellip; f1,f0 编码尾数M, 但是编码出来的值也依赖于阶码字 段的值是否等千0 。 在开始时记住一些值的来源：E = exp - Bias；M = 1/0 + f\n规格化的值 当阶数 exp ≠ 000…0和 exp ≠ 111…1时，表示的其实都是规范化的值，这里只需要大概知道因为实数轴上原来连续的值会被规范到有限的定值上并且这些定值之间的间距也是不一样的，具体可以通过后面给出的例子来理解。\n当 exp 的位模式既不全为0(数值0), 也不全为(32位的255，64位的2047)的时候，frac可以随意取值；\nE = exp - Bias(2[^w-1] - 1) M = 1 + f; 例子：\n1 2 3 4 12345 = 0b0011.0000.0011.1001 = 1.1000000111001 * 2[^13] E = 13 = exp - 127 -\u0026gt; exp = 140; M = 1 + f = 1.1000000111001 -\u0026gt; f = 1000000111001; s(1) exp(8) frac(23) 0 10001100 10000001110010000000000 非规格化的值 当exp每一位都为0的时候，可以想象到这时候的数无限的接近数值0，可画个数轴来看，此时的 E = 1 - Bias而且M没有隐含的1表示了，M = f\n第一个功能就是表示0，0的时候exp位为0，frac位为0，符号位的不同使得-0/+0有相同的地方何不同的地方。\n非规格化数的另外一个功能是表示那些非常接近于0.0 的数。它们提供了一种属性，称为逐渐溢出(gradual underflow), 其中，可能的数值分布均匀地接近于0.0 。\n无穷大和NaN 最后一类数值是当指阶码全为1 的时候出现的。当小数域全为0时，得到的值表示无穷，当 s=O 时是 +∞ 或者是 s=1 时是 -∞ 。当我们把两个非常大的数相乘，或者除以零时，无穷能够表示溢出的结果。当小数域为非零时，结果值被称为\u0026quot;NaN\u0026quot;, 即“不是一个数(Not a Number)\u0026quot; 的缩写。一些运算的结果不能是实数或无穷，就会返回这样的NaN值，比如当计算sqrt(-1)或 (∞-∞) 时。在某些应用中，表示未初始化的数据时，它们也很有用处。\n练习 假设一个基于IEEE 浮点格式的5 位浮点表示，有1 个符号位、2 个阶 码位(k=Z) 和两个小数位(n=2) 。阶码偏置量是2[2-1] - 1 = 1 。下表中列举了这个5 位浮点表示的全部非负取值范围。使用下面的条件，填写表格中的空白项：\ne: 假定阶码字段是一个无符号整数所表示的值。\nE: 偏置之后的阶码值。\n2[^E]: 阶码的权重。\nf: 小数值。\nM: 尾数的值。\n2[^E] * M: 该数（未归约的）小数值。\nV: 该数归约后的小数值。\n十进制：该数的十进制表示。\n位 e E 2[^E] f M 2[^E]*M V 十进制 0 00 00 0 0 1 0/4 0/4 0/4 0 0.0 0 00 01 0 0 1 1/4 1/4 1/4 1/4 0.25 0 00 10 0 0 1 2/4 2/4 2/4 1/2 0.5 0 00 11 0 0 1 3/4 3/4 3/4 3/4 0.75 0 01 00 1 0 1 0/4 4/4 4/4 1 1.0 0 01 01 1 0 1 1/4 5/4 5/4 5/4 1.25 0 01 10 1 0 1 2/4 6/4 6/4 3/2 1.5 0 01 11 1 0 1 3/4 7/4 7/4 7/4 1.75 0 10 00 2 1 2 0/4 4/4 8/4 2 2.0 0 10 01 2 1 2 1/4 5/4 10/4 5/2 2.5 0 10 10 2 1 2 2/4 6/4 12/4 3 3.0 0 10 11 2 1 2 3/4 7/4 14/4 7/2 3.5 0 11 00 - - - - - - ∞ - 0 11 01 - - - - - - NaN - 0 11 10 - - - - - - NaN - 0 11 11 - - - - - - NaN - 浮点数的舍入 溢出 1 2 3 4 printf(\u0026#34;浮点数的溢出:\\n\\t\u0026#34;); printf(\u0026#34;(1e20 + (-1e20)) + 3.14 = %lf\\n\\t\u0026#34;, 1e20 + (-1e20) + 3.14); printf(\u0026#34;1e20 + (-1e20 + 3.14) = %lf\\n\u0026#34;, 1e20 + (-1e20 + 3.14)); 浮点数的加乘法 浮点数的加乘法是和我们想的不一样的，它不满足结合律，交换律的，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 x = a + b + c; y = b + c + d; // 编译器可能试图通过产生下列代码来省去一个浮点加法 t = b + c; x = a + t; y = t + d; // 但是对x来说，这个计算可能会产生于原始值不同的值,因为它使用了加法运算的不同结合方式 //浮点数的溢出: (1e20 + (-1e20)) + 3.14 = 3.140000 1e20 + (-1e20 + 3.14) = 0.000000 总结 这一章我们具体的学习了在机器上数的表示，我们用无符号数和补码来表示我的数值，用浮点数表示二进制的科学计数法，数与数的计算，它们是会有溢出的，用模运算来截断防止位溢出。 大多数C 语言实现遵循的原则是底层的位模式不变。在补码机器上，对于一个w 位的值，这种行为是由函数T2Uw 和U2Tw来描述的。C 语言隐式的强制类型转换会出现许多程序员无法预计的结果，常常导致程序错误。\n1 2 int y = (int)(double)y; 我的建议是通读一遍课本，课本比我写的好很多，我想表达的写不出来那个味道，而后再去看看视频会更加的理解。\n外部链接 IEEE754\u0026mdash;wiki 浮点数\u0026mdash;wiki\n","date":"2023-03-19T20:13:06+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/%E4%B8%80.%E6%95%B0%E7%9A%84%E8%A1%A8%E7%A4%BAcsapp/","title":"一.数的表示(CSAPP)"},{"content":"前言 有志，有识，有恒，则断无不成之事 我自己在2022年学习过CS61c，这门课主要是讲解了计算机的体系结构，终于踏入了计算机的门槛。计算机体系结构，这是一个计算机十分难啃的一门知识，内容之多、范围之广，无论里面的数的表示、编译原理、CPU的基本架构、内存、虚拟内存、流水线、线程级并行、I/O、OS、网络等等，每个方面都可以单独拎出来成为一门课程。而想要精通这些知识需要耗费大量的时间和精力，即使学习十年也不嫌少。哈哈哈。\n我对计算机的热爱促使我非正式地学习了 CS61c（可惜我不是伯克利的学子）过后，我发现，它给我的是课堂上没有的一些思想，比如：为什么？通过已经有的事实发出提问（即存在有缘由，而不是想当然的存在即真理）。\n在我上大学的时候我就知道一本神书《深入理解计算机系统》（即：《Computer Systems: A Programmer’s Perspective》），可是一直没有机会读一读（也看不懂 😂 ，也正是在有CS61c的基础上我想去好好的通读一遍它。\n这本书好在哪里？它是一本以程序员的视角来看计算机的底层机制，不需要你对物理，电子层面有多么高的水准来看计算机，如果有的话更好的（在这里就不得不吐槽国内的教学了）。它里面的内容也是十分的丰富，结合了计算机组成与体系结构，链接与装载，程序优化，内存存储层次，操作系统，网络等基础知识。\n好的，说那么多，我也想把我在学习的过程写下来这也不失成为我的一场回忆。\n学习目的 知其然而不知其所以然\n在看这本书的时候问问自己，这本书可以给我带来什么？我为什么要学习这本书？正如上面的这句话一样，况且我也不想做一个”代码的搬运工“。\n学到什么？ 可以对计算机底层系统有一个更加全面且深入的认识。 系统的理解计算机系统底层的工作原理。 写出更加健壮的、安全的代码。 走向现实层面的计算机。 打下编译原理、操作系统的基础。 等等 学习是要你静下心来，认真思考，积极动手的，用我的话来说就是：事无巨细\n计算机系统漫游 接下来就看看我们要学什么。\n信息bit化 人类与机器交互最大的问题是语言不通。让我们回到五六十年代，那时没有像现在这样方便的手机、iPad和电脑操作方式。那个\u0026quot;古老时代\u0026quot;没有图像、键盘或字符，只有打孔器、巨型电子管和满屋子的电线\u0026hellip;\u0026hellip;我们唯一能与计算机交流的方法就是通过电流和“疯狂”的思维。\n而随着物理学和数学的发展，计算机得以快速发展，并且我们开始使用二进制来与机器进行交互，这比以前好多了。\n但仍然存在一个问题：“为什么要使用二进制？”因为它适用于我们的电路（高/低电压）和逻辑门（0/1），似乎所有事情都变成了二进制。 我们在这里已经迈出了很大的步伐。\n在计算机领域里面，我们叫一个可以正常显示0/1的位叫bit，而后续的研究证明了一次性对8bit进行操作是十分成功的，因此1 Byte = 8 bit(注意大小写)，在后面我们的位越来越多，我们使用了十六进制。由此来看，人类是很富有想象力的种族。\n在后面的学习中，数值的表示是很重要的知识点，计算机就是为精准，快速计算这些数值，特别是浮点数（float）的计算而发展的。\n编译系统 1 2 3 4 5 6 7 8 9 10 int main() { printf(\u0026#34;Hello World\\n\u0026#34;); return 0; } 上面是一个简单的C语言程序，打印一个\u0026quot;Hello World\u0026quot;(并且换行)，但是，它要经过好几个步骤才能打印在你的屏幕上，分别是：编译(Compiler)，汇编(Assembler)，装载器(Loader)，链接器(Linker)。\n我们在这一部分将要学到从 高级语言 --\u0026gt; 汇编语言 --\u0026gt; 机器语言 这一过程的具体实现，这使我们能够更深入地了解系统的底层。。\nCPU基本结构 CPU（中央处理器），可以说是本世纪最伟大的发明了，一个小小的芯片装载着人类的智慧，这一部分我们要了解 CPU 的内部构造，下面是一张 CPU 的大致图片：\n这是一个复杂但十分有趣的部分，相信我，你会体会它的魅力的。\n操作系统 操作系统(Operating System)，是来控制电脑的执行硬件、软件资源，控制I/O操作，提供基本的用户互动等。\n它也负责加载程序、处理服务（如网络堆栈和文件系统）以及为多个程序复用资源，但它实际上是要负责隔离各个程序，使得一个给定的程序不会干扰另一个程序的内存或执行。\n网络通信 这一部分我也写了自己的学习笔记\n外部链接 Computer Science from the Bottom Up\n小土刀博主的『读薄』\nfengmuzi2003up主的计算机系统漫游\n","date":"2023-03-12T21:46:39+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/%E9%9B%B6.%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9Fcsapp/","title":"零.深入理解计算机系统(CSAPP)"},{"content":"什么是Internet 网络中的网络\n因特网是一个覆盖数以万计个计算设备的网络，它们是由无数的端系统通过通信链路和分组交换机连接在一起的，我们的网络设备是充当网络中的端系统（网络边缘），而现在比较常见的路由器和链路层交换机是我们的网络核心，而一些链路等物理设备是我们的物理媒体。\n我喜欢在学习一个新知识的时候运用类比则比较方便快速的了解： 在现代城市里面高速公路并不少见，某天小明要从家到市图书馆借书，他从家出来发现他家和其他房子共用一道小点的道路，刚走出街口时道路随之变宽了，途中经历了几个红绿灯，公路也越来越宽，等到达图书馆的时候需要一个身份证明最后才能进入，最后借好书根据原路返回了。\n这就是一个网络的路径，而文中的身份证明在网络中叫作协议，在后面的学习中我们就是要学习网络协议。\n什么是协议 简单讲就是网络自己的规定，它是有着自己的判定标准，比如：我们人类之间的聊天就是在进行自己的标准，我们会依据他人的问题作出反馈，但是对一些故意找茬的主动屏蔽。网络的协议是：对两个及其以上的通信设备之间互换报文告知网络核心格式和顺序以及接收发送等动作。\n从服务角度 我们的电脑要怎么和远距离的设备进行发送数据？ 它们是使用着通信设施的分布式应用，通过分布的方法和其他端设备连接，而端系统有着一套规则集合套接字接口。\n网络边缘 可以连接互联网的都是端系统\n不知道你是否使用过git吗？这是一个好用的工具在学习中，他的原理简单讲就是把设备看作主机，既然是主机就有一切的修改。我需要知道的是主机就是网络中的端系统，在我们的抽象里面它们位于边缘，也就是网络边缘。主分两种：客户端 \u0026amp; 服务器。一般服务器管理多个客户端。看看一些互联网大公司里面的服务器，都是成千上万的数量级。\n连接服务 TCP 这么多的数量要怎么控制，协议TCP(Transmission Control Protocol),这是一个十分基础的协议将控制消息的接收和发送，是一个可靠的，还能控制流量。\nUDP User Datagram Protocol 用户数据协议，一种无连接的服务，之和端系统有关和核心没关，一般用在流媒体上。\n","date":"2023-03-10T21:08:35+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/%E4%B8%80.network-internet/","title":"一.Network \u0026 Internet"},{"content":"前言 这是一个根据《计算机网络：自顶向下方法》为主要课本的个人学习笔记。\n导读 在学习计算机的时候不可避免的是网络这个和我们现代生活息息相关的部分。其实在我之前看来，网络是一种我们看不见的东西，它无处不在，你看看你手边的手机，现在眼前的电脑\u0026hellip;\u0026hellip;他们之间有一种莫名的联系，有无形的线使它们链接起来\n当今世界，计算机网络已经成为了人们生活中不可或缺的一部分，它的影响不仅仅只 限于信息交流领域，还涉及到了商业、政治、文化等各个方面。作为一个十分复杂的系统，计算机网络的出现极大地改变了社会的基本交流规律。通过数以万计的网络连接，世界各地的人或物之间得以深度联系，信息的交流、共享和传递变得更加快捷和方便。\n网络的连接也让人们之间的思想交流变得更加广泛、自由与便捷。在这个信息化的时代，网络已经成为了人们相互交流、了解世界的重要途径之一，它让人们能够更加深入地了解各种文化、传统和观点，从而更好地认识自己和他人，增进人类之间的理解和和谐。\n然而，与此同时，网络连接也带来了许多不稳定的因素，例如网络病毒、黑客攻击、网络诈骗等等。这些不利因素威胁着人们信息的安全和隐私，使得网络世界变得更加复杂和危险。因此，在使用网络的过程中，我们必须注意保护自己的信息安全，提高自我保护意识，防范网络风险。\n在我学习计算机网络的过程，《自顶向下》是一本十分优秀的教材，它通过逐层递进的方式，深入浅出地讲解了计算机网络的基本概念和原理，帮助读者快速入门，并逐渐提高自己的网络知识水平。通过学习这本书，可以让我们更好地了解网络的繁星点点，理解计算机网络的运作方式和工作原理，从而更好地掌握网络知识，提高我们的网络应用能力。\n外部链接 中科大郑烇、杨坚全套《计算机网络（自顶向下方法 第7版》\n","date":"2023-03-08T21:08:30+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/%E9%9B%B6.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AF%BC%E8%AF%BB/","title":"零.计算机网络导读"},{"content":"前言 在计算机里面，所有的数据都是以二进制来进行存储的, 那么，我们在计算的时候不仅仅要知道十进制的计算， 也要知道二进制的计算 （+、-、*、/），这些都是叫位运算，即将符号位共同参与运算的运算。\n位运算的种类 接下来来看看有哪些运算\n符号 描述 作用 + 加法 用二进制的方法进行加法运算 - 减法 用二进制的方法进行加法运算 \u0026amp; 与运算 两个位都为1时，结果才为1 | 或运算 两个位都为0时，结果才为0 ^ 异或运算 两个位相同为0，相异为1 ~ 反取 0反1，1反0 \u0026laquo; 左移运算 所有二进位全部左移位，高位丢弃，低位补0 \u0026raquo; 右移运算 所有二进位全部右移位，对无符号数，高位补0；有符号数，各编译器处理方法不一样，有的补符号位（算术右移），有的补0（逻辑右移） 计算方式 加法和减法就不再过多赘述！！！\n\u0026lsquo;\u0026amp;\u0026rsquo; 与运算 和AND一样\n1 2 3 4 0 \u0026amp; 0 = 0 0 \u0026amp; 1 = 0 1 \u0026amp; 0 = 0 1 \u0026amp; 1 = 1 负数按补码形式参加按位与运算。\n\u0026lsquo;|\u0026rsquo; 或运算 和OR一样\n1 2 3 4 0 | 0 = 0 0 | 1 = 1 1 | 0 = 1 1 | 1 = 1 负数按 补码 形式参加按位或运算。\n\u0026lsquo;^\u0026rsquo; 异或运算 和AOR一样\n1 2 3 4 0 ^ 0 = 0 0 ^ 1 = 1 1 ^ 0 = 1 1 ^ 1 = 0 \u0026lsquo;~\u0026rsquo; 取反运算 与NOT一样\n1 2 ~1 = 0 ~0 = 1 \u0026lsquo;\u0026laquo;\u0026rsquo; 和 \u0026lsquo;\u0026raquo;\u0026rsquo; 左右位移运算 将一个运算对象的各二进制位全部左（右）移若干位左(右)边的二进制位丢弃，右边补0\n1 2 3 a = 1010 0101; # a \u0026lt;\u0026lt; (\u0026gt;\u0026gt;) n a \u0026lt;\u0026lt; 2 --------- \u0026gt; a = 1001 0100; a \u0026gt;\u0026gt; 2 --------- \u0026gt; a = 0010 1001; 总结 在进行计算的时候，计算机中的数在内存中都是以二进制形式进行存储的，用位运算就是直接对整数在内存中的二进制位进行操作，因此其执行效率非常高，在程序中尽量使用位运算进行操作，这不仅可以锻炼自己的二进制运算，还会大大提高程序的性能。\n外部链接 此博客参考菜鸟教程-C语言中的位运算\n","date":"2022-11-10T21:04:43+08:00","permalink":"https://FeiNiaoBF.github.io/zh-cn/p/%E5%A5%87%E5%A6%99%E7%9A%84%E4%BD%8D%E8%BF%90%E7%AE%97/","title":"奇妙的位运算"}]